{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# READ THE CSV INTO DATAFRAME\n",
    "\n",
    "df = pd.read_csv('Syngenta/Syngenta_2017/Experiment_dataset.csv')\n",
    "# df2 = pd.read_csv('Syngenta/Syngenta_2017/Region_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE SOME OPTIONAL INFORMATION ABOUT THE DATAFRAME\n",
    "\n",
    "# print(df.head())\n",
    "# print(df.describe())\n",
    "print(df)\n",
    "print(df.Variety.unique(), \"\\nthere are \", len(df.Variety.unique()), \" unique varieties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Yield', 'Year', 'Temperature', 'Precipitation', 'Solar Radiation',\n",
      "       'Soil class', 'CEC', 'Organic matter', 'pH', 'Clay', 'Silt', 'Sand',\n",
      "       'Area'],\n",
      "      dtype='object')\n",
      "             0    1         2         3         4         5         6   \\\n",
      "0      0.457460  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "1      0.441596  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "2      0.402939  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "3      0.435585  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "4      0.364699  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "5      0.388912  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "6      0.403440  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "7      0.354012  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "8      0.418803  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "9      0.421558  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "10     0.585789  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "11     0.540870  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "12     0.567838  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "13     0.617183  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "14     0.400601  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "15     0.368874  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "16     0.416465  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "17     0.428571  0.0  0.361879  0.577475  0.410389  0.049550  0.811016   \n",
      "18     0.585789  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "19     0.545379  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "20     0.549887  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "21     0.594723  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "22     0.527428  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "23     0.576772  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "24     0.581281  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "25     0.398347  0.0  0.413783  0.494527  0.349513  0.009009  0.642077   \n",
      "26     0.351173  0.0  0.413783  0.494527  0.349513  0.009009  0.642077   \n",
      "27     0.540870  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "28     0.540870  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "29     0.581281  0.0  0.467931  0.286548  0.196814  0.459459  0.361722   \n",
      "...         ...  ...       ...       ...       ...       ...       ...   \n",
      "82006  0.486683  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82007  0.493613  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82008  0.441680  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82009  0.456375  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82010  0.482675  1.0  0.454973  0.574921  0.049593  0.049550  0.347931   \n",
      "82011  0.445270  1.0  0.454973  0.574921  0.049593  0.049550  0.347931   \n",
      "82012  0.472238  1.0  0.454973  0.574921  0.049593  0.049550  0.347931   \n",
      "82013  0.471070  1.0  0.454973  0.574921  0.049593  0.049550  0.347931   \n",
      "82014  0.488854  1.0  0.454973  0.574921  0.049593  0.049550  0.347931   \n",
      "82015  0.404609  1.0  0.454973  0.574921  0.049593  0.049550  0.347931   \n",
      "82016  0.576271  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82017  0.539618  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82018  0.545546  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82019  0.531853  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82020  0.541705  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82021  0.463305  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82022  0.478918  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82023  0.507473  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82024  0.492694  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82025  0.485764  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82026  0.486432  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82027  0.477165  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82028  0.544043  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82029  0.514319  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82030  0.608834  1.0  0.682460  0.460472  0.198329  0.459459  0.578606   \n",
      "82031  0.445103  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82032  0.426902  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82033  0.491024  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82034  0.456375  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "82035  0.452868  1.0  0.753547  0.615057  0.158504  0.459459  0.245134   \n",
      "\n",
      "             7         8         9         10        11        12  \n",
      "0      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "1      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "2      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "3      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "4      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "5      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "6      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "7      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "8      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "9      0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "10     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "11     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "12     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "13     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "14     0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "15     0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "16     0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "17     0.203557  0.499232  0.461144  0.328767  0.594016  0.323134  \n",
      "18     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "19     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "20     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "21     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "22     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "23     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "24     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "25     0.189762  0.408568  0.511745  0.752372  0.212336  0.466579  \n",
      "26     0.189762  0.408568  0.511745  0.752372  0.212336  0.466579  \n",
      "27     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "28     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "29     0.229585  0.450144  0.160675  0.272692  0.758996  0.642321  \n",
      "...         ...       ...       ...       ...       ...       ...  \n",
      "82006  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82007  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82008  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82009  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82010  0.236557  0.521504  0.361176  0.461770  0.520941  0.702967  \n",
      "82011  0.236557  0.521504  0.361176  0.461770  0.520941  0.702967  \n",
      "82012  0.236557  0.521504  0.361176  0.461770  0.520941  0.702967  \n",
      "82013  0.236557  0.521504  0.361176  0.461770  0.520941  0.702967  \n",
      "82014  0.236557  0.521504  0.361176  0.461770  0.520941  0.702967  \n",
      "82015  0.236557  0.521504  0.361176  0.461770  0.520941  0.702967  \n",
      "82016  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82017  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82018  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82019  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82020  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82021  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82022  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82023  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82024  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82025  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82026  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82027  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82028  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82029  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82030  0.166117  0.360359  0.435103  0.932380  0.086989  0.795344  \n",
      "82031  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82032  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82033  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82034  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "82035  0.147740  0.381352  0.175201  0.713183  0.377305  0.587495  \n",
      "\n",
      "[82036 rows x 13 columns]\n",
      "Yield has correlation [2438155.42564917] with yield\n",
      "Year has correlation [3260451.29499999] with yield\n",
      "Temperature has correlation [2160759.30634827] with yield\n",
      "Precipitation has correlation [2151187.69218195] with yield\n",
      "Solar Radiation has correlation [1608548.11212687] with yield\n",
      "Soil class has correlation [1530292.0245946] with yield\n",
      "CEC has correlation [2922193.25387557] with yield\n",
      "Organic matter has correlation [1384113.87219878] with yield\n",
      "pH has correlation [2526786.97093114] with yield\n",
      "Clay has correlation [2029012.02539768] with yield\n",
      "Silt has correlation [2513717.4553957] with yield\n",
      "Sand has correlation [2162157.87827142] with yield\n",
      "Area has correlation [2643209.70050482] with yield\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL CORRELATION CHECKER\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# x = df.values #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# df = pandas.DataFrame(x_scaled)\n",
    "\n",
    "#these were selected mainly due to their dtype\n",
    "df_potential_columns = df.drop(['Experiment', 'Location', 'Planting date', 'Check Yield', 'Yield difference', 'Latitude', 'Longitude', 'Variety', 'PI'], axis=1).columns\n",
    "# potential_feature_columns = ['Location', 'Temperature', 'Precipitation', 'Solar Radiation', 'Soil class', 'CEC', 'pH', 'Clay', 'Silt', 'Sand', 'Area']\n",
    "# print(potential_feature_columns)\n",
    "potential_output_column = df.Yield\n",
    "\n",
    "new_df = df.loc[:, df_potential_columns]\n",
    "print(new_df.columns)\n",
    "\n",
    "potential_X = df.loc[:, df_potential_columns].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(potential_X)\n",
    "potential_y = potential_output_column\n",
    "df2 = pd.DataFrame(x_scaled)\n",
    "print(df2)\n",
    "\n",
    "for x in df2:\n",
    "    print(\"%s has correlation %s with yield\" % (df.loc[:, df_potential_columns].iloc[:, x].name, np.correlate(df2[x], potential_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREVIOUSLY USED ONEHOT ENCODER\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas import Series\n",
    "le = LabelEncoder()\n",
    "integer_encoded = le.fit_transform(df.Variety)\n",
    "# le.classes_\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "print(onehot_encoded)\n",
    "\n",
    "# df['VarietyEncode'] = onehot_encoded\n",
    "# print(pd.get_dummies(df.Variety))\n",
    "# print(df.Variety)\n",
    "    \n",
    "from numpy import argmax\n",
    "inverted = le.inverse_transform([argmax(onehot_encoded[300, :])])\n",
    "print([argmax(onehot_encoded[300, :])])\n",
    "verted = le.transform(['V150834'])\n",
    "print(inverted)\n",
    "# inverted = le.inverse_transform([df.])\n",
    "# print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL USED FROM CONVERTING EACH VARIETY TO A ONE HOT\n",
    "\n",
    "def convert_variety_to_one_hot(variety):\n",
    "    return onehot_encoded[le.transform([variety])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL APPLY ABOVE FUNCTION TO REPLACE EACH ROW IN VARIETY COLUMN WITH ONE HOT REPRESENTATION\n",
    "\n",
    "df.Variety = df.Variety.apply(lambda val: convert_variety_to_one_hot(val))\n",
    "\n",
    "# OPTIONAL RESHAPE\n",
    "df.Variety = df.Variety.apply(lambda val: val.reshape(174))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Experiment  Location  Variety Planting date  Yield  Check Yield  \\\n",
      "0      09SUBWYG201      2291  V000047       5/20/09  55.62        53.61   \n",
      "1      09SUBWYG202      2291  V000047       5/20/09  53.72        53.61   \n",
      "2      09SUBWYG203      2291  V000047       5/20/09  49.09        53.61   \n",
      "3      09SUBWYG204      2291  V000047       5/20/09  53.00        53.61   \n",
      "4      09SUBWYG301      2290  V130307        5/8/09  44.51        57.32   \n",
      "5      09SUBWYG301      2290  V000025        5/8/09  47.41        57.32   \n",
      "6      09SUBWYG302      2290  V000024        5/8/09  49.15        57.32   \n",
      "7      09SUBWYG302      2290  V130307        5/8/09  43.23        57.32   \n",
      "8      09SUBWYG302      2290  V000124        5/8/09  50.99        57.32   \n",
      "9      09SUBWYG302      2290  V000025        5/8/09  51.32        57.32   \n",
      "10     09SUBWYG302      3490  V000024       5/26/09  70.99        61.90   \n",
      "11     09SUBWYG302      3490  V130307       5/26/09  65.61        61.90   \n",
      "12     09SUBWYG302      3490  V000124       5/26/09  68.84        61.90   \n",
      "13     09SUBWYG302      3490  V000025       5/26/09  74.75        61.90   \n",
      "14     09SUBWYG304      2290  V139094        5/8/09  48.81        57.32   \n",
      "15     09SUBWYG304      2290  V000024        5/8/09  45.01        57.32   \n",
      "16     09SUBWYG304      2290  V000023        5/8/09  50.71        57.32   \n",
      "17     09SUBWYG304      2290  V000124        5/8/09  52.16        57.32   \n",
      "18     09SUBWYG304      3490  V139094       5/26/09  70.99        61.90   \n",
      "19     09SUBWYG304      3490  V000024       5/26/09  66.15        61.90   \n",
      "20     09SUBWYG304      3490  V000023       5/26/09  66.69        61.90   \n",
      "21     09SUBWYG304      3490  V000124       5/26/09  72.06        61.90   \n",
      "22     09SUBWYG306      3490  V000125       5/26/09  64.00        61.90   \n",
      "23     09SUBWYG306      3490  V000051       5/26/09  69.91        61.90   \n",
      "24     09SUBWYG306      3490  V000025       5/26/09  70.45        61.90   \n",
      "25     09SUBWYG309      3210  V000051       5/11/09  48.54        64.12   \n",
      "26     09SUBWYG309      3210  V000025       5/11/09  42.89        64.12   \n",
      "27     09SUBWYG309      3490  V000051       5/28/09  65.61        61.90   \n",
      "28     09SUBWYG309      3490  V000025       5/28/09  65.61        61.90   \n",
      "29     09SUBWYG310      3490  V000051       5/28/09  70.45        61.90   \n",
      "...            ...       ...      ...           ...    ...          ...   \n",
      "82006  15SUSGYGY23      3395  V137136        6/6/15  59.12        55.49   \n",
      "82007  15SUSGYGY23      3395  V113396        6/6/15  59.95        55.49   \n",
      "82008  15SUSGYGY23      3395  V152440        6/6/15  53.73        55.49   \n",
      "82009  15SUSGYGY23      3395  V120047        6/6/15  55.49        55.49   \n",
      "82010  15SUSGYGY23      3435  V152779        6/5/15  58.64        53.36   \n",
      "82011  15SUSGYGY23      3435  V121015        6/5/15  54.16        53.36   \n",
      "82012  15SUSGYGY23      3435  V137136        6/5/15  57.39        53.36   \n",
      "82013  15SUSGYGY23      3435  V113396        6/5/15  57.25        53.36   \n",
      "82014  15SUSGYGY23      3435  V152440        6/5/15  59.38        53.36   \n",
      "82015  15SUSGYGY23      3435  V120047        6/5/15  49.29        53.36   \n",
      "82016  15SUSGYGY24      3325  V121015        6/6/15  69.85        58.72   \n",
      "82017  15SUSGYGY24      3325  V137136        6/6/15  65.46        58.72   \n",
      "82018  15SUSGYGY24      3325  V113396        6/6/15  66.17        58.72   \n",
      "82019  15SUSGYGY24      3325  V152440        6/6/15  64.53        58.72   \n",
      "82020  15SUSGYGY24      3325  V136868        6/6/15  65.71        58.72   \n",
      "82021  15SUSGYGY24      3395  V121015        6/6/15  56.32        55.49   \n",
      "82022  15SUSGYGY24      3395  V137136        6/6/15  58.19        55.49   \n",
      "82023  15SUSGYGY24      3395  V113396        6/6/15  61.61        55.49   \n",
      "82024  15SUSGYGY24      3395  V152440        6/6/15  59.84        55.49   \n",
      "82025  15SUSGYGY24      3395  V136868        6/6/15  59.01        55.49   \n",
      "82026  15SUSGYGY25      3325  V121015        6/6/15  59.09        58.72   \n",
      "82027  15SUSGYGY25      3325  V137136        6/6/15  57.98        58.72   \n",
      "82028  15SUSGYGY25      3325  V113396        6/6/15  65.99        58.72   \n",
      "82029  15SUSGYGY25      3325  V152440        6/6/15  62.43        58.72   \n",
      "82030  15SUSGYGY25      3325  V136868        6/6/15  73.75        58.72   \n",
      "82031  15SUSGYGY25      3395  V121015        6/6/15  54.14        55.49   \n",
      "82032  15SUSGYGY25      3395  V137136        6/6/15  51.96        55.49   \n",
      "82033  15SUSGYGY25      3395  V113396        6/6/15  59.64        55.49   \n",
      "82034  15SUSGYGY25      3395  V152440        6/6/15  55.49        55.49   \n",
      "82035  15SUSGYGY25      3395  V136868        6/6/15  55.07        55.49   \n",
      "\n",
      "       Yield difference  Year   Latitude  Longitude   ...     V156565  \\\n",
      "0                  2.01  2009  42.019111 -93.525735   ...           0   \n",
      "1                  0.11  2009  42.019111 -93.525735   ...           0   \n",
      "2                 -4.52  2009  42.019111 -93.525735   ...           0   \n",
      "3                 -0.61  2009  42.019111 -93.525735   ...           0   \n",
      "4                -12.81  2009  42.016877 -93.526748   ...           0   \n",
      "5                 -9.90  2009  42.016877 -93.526748   ...           0   \n",
      "6                 -8.17  2009  42.016877 -93.526748   ...           0   \n",
      "7                -14.09  2009  42.016877 -93.526748   ...           0   \n",
      "8                 -6.33  2009  42.016877 -93.526748   ...           0   \n",
      "9                 -5.99  2009  42.016877 -93.526748   ...           0   \n",
      "10                 9.09  2009  40.699070 -86.900038   ...           0   \n",
      "11                 3.71  2009  40.699070 -86.900038   ...           0   \n",
      "12                 6.94  2009  40.699070 -86.900038   ...           0   \n",
      "13                12.85  2009  40.699070 -86.900038   ...           0   \n",
      "14                -8.51  2009  42.016877 -93.526748   ...           0   \n",
      "15               -12.30  2009  42.016877 -93.526748   ...           0   \n",
      "16                -6.61  2009  42.016877 -93.526748   ...           0   \n",
      "17                -5.16  2009  42.016877 -93.526748   ...           0   \n",
      "18                 9.09  2009  40.699070 -86.900038   ...           0   \n",
      "19                 4.25  2009  40.699070 -86.900038   ...           0   \n",
      "20                 4.79  2009  40.699070 -86.900038   ...           0   \n",
      "21                10.16  2009  40.699070 -86.900038   ...           0   \n",
      "22                 2.10  2009  40.699070 -86.900038   ...           0   \n",
      "23                 8.01  2009  40.699070 -86.900038   ...           0   \n",
      "24                 8.55  2009  40.699070 -86.900038   ...           0   \n",
      "25               -15.59  2009  41.272980 -91.666230   ...           0   \n",
      "26               -21.24  2009  41.272980 -91.666230   ...           0   \n",
      "27                 3.71  2009  40.699070 -86.900038   ...           0   \n",
      "28                 3.71  2009  40.699070 -86.900038   ...           0   \n",
      "29                 8.55  2009  40.699070 -86.900038   ...           0   \n",
      "...                 ...   ...        ...        ...   ...         ...   \n",
      "82006              3.63  2015  39.153770 -87.879040   ...           0   \n",
      "82007              4.46  2015  39.153770 -87.879040   ...           0   \n",
      "82008             -1.77  2015  39.153770 -87.879040   ...           0   \n",
      "82009             -0.01  2015  39.153770 -87.879040   ...           0   \n",
      "82010              5.29  2015  40.225240 -83.844521   ...           0   \n",
      "82011              0.81  2015  40.225240 -83.844521   ...           0   \n",
      "82012              4.03  2015  40.225240 -83.844521   ...           0   \n",
      "82013              3.90  2015  40.225240 -83.844521   ...           0   \n",
      "82014              6.03  2015  40.225240 -83.844521   ...           0   \n",
      "82015             -4.07  2015  40.225240 -83.844521   ...           0   \n",
      "82016             11.12  2015  39.697050 -89.962130   ...           0   \n",
      "82017              6.73  2015  39.697050 -89.962130   ...           0   \n",
      "82018              7.45  2015  39.697050 -89.962130   ...           0   \n",
      "82019              5.81  2015  39.697050 -89.962130   ...           0   \n",
      "82020              6.99  2015  39.697050 -89.962130   ...           0   \n",
      "82021              0.82  2015  39.153770 -87.879040   ...           0   \n",
      "82022              2.69  2015  39.153770 -87.879040   ...           0   \n",
      "82023              6.11  2015  39.153770 -87.879040   ...           0   \n",
      "82024              4.35  2015  39.153770 -87.879040   ...           0   \n",
      "82025              3.52  2015  39.153770 -87.879040   ...           0   \n",
      "82026              0.36  2015  39.697050 -89.962130   ...           0   \n",
      "82027             -0.74  2015  39.697050 -89.962130   ...           0   \n",
      "82028              7.27  2015  39.697050 -89.962130   ...           0   \n",
      "82029              3.71  2015  39.697050 -89.962130   ...           0   \n",
      "82030             15.03  2015  39.697050 -89.962130   ...           0   \n",
      "82031             -1.35  2015  39.153770 -87.879040   ...           0   \n",
      "82032             -3.53  2015  39.153770 -87.879040   ...           0   \n",
      "82033              4.14  2015  39.153770 -87.879040   ...           0   \n",
      "82034             -0.01  2015  39.153770 -87.879040   ...           0   \n",
      "82035             -0.42  2015  39.153770 -87.879040   ...           0   \n",
      "\n",
      "       V156574  V156642  V156763  V156774  V156783  V156786  V156797  V156806  \\\n",
      "0            0        0        0        0        0        0        0        0   \n",
      "1            0        0        0        0        0        0        0        0   \n",
      "2            0        0        0        0        0        0        0        0   \n",
      "3            0        0        0        0        0        0        0        0   \n",
      "4            0        0        0        0        0        0        0        0   \n",
      "5            0        0        0        0        0        0        0        0   \n",
      "6            0        0        0        0        0        0        0        0   \n",
      "7            0        0        0        0        0        0        0        0   \n",
      "8            0        0        0        0        0        0        0        0   \n",
      "9            0        0        0        0        0        0        0        0   \n",
      "10           0        0        0        0        0        0        0        0   \n",
      "11           0        0        0        0        0        0        0        0   \n",
      "12           0        0        0        0        0        0        0        0   \n",
      "13           0        0        0        0        0        0        0        0   \n",
      "14           0        0        0        0        0        0        0        0   \n",
      "15           0        0        0        0        0        0        0        0   \n",
      "16           0        0        0        0        0        0        0        0   \n",
      "17           0        0        0        0        0        0        0        0   \n",
      "18           0        0        0        0        0        0        0        0   \n",
      "19           0        0        0        0        0        0        0        0   \n",
      "20           0        0        0        0        0        0        0        0   \n",
      "21           0        0        0        0        0        0        0        0   \n",
      "22           0        0        0        0        0        0        0        0   \n",
      "23           0        0        0        0        0        0        0        0   \n",
      "24           0        0        0        0        0        0        0        0   \n",
      "25           0        0        0        0        0        0        0        0   \n",
      "26           0        0        0        0        0        0        0        0   \n",
      "27           0        0        0        0        0        0        0        0   \n",
      "28           0        0        0        0        0        0        0        0   \n",
      "29           0        0        0        0        0        0        0        0   \n",
      "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "82006        0        0        0        0        0        0        0        0   \n",
      "82007        0        0        0        0        0        0        0        0   \n",
      "82008        0        0        0        0        0        0        0        0   \n",
      "82009        0        0        0        0        0        0        0        0   \n",
      "82010        0        0        0        0        0        0        0        0   \n",
      "82011        0        0        0        0        0        0        0        0   \n",
      "82012        0        0        0        0        0        0        0        0   \n",
      "82013        0        0        0        0        0        0        0        0   \n",
      "82014        0        0        0        0        0        0        0        0   \n",
      "82015        0        0        0        0        0        0        0        0   \n",
      "82016        0        0        0        0        0        0        0        0   \n",
      "82017        0        0        0        0        0        0        0        0   \n",
      "82018        0        0        0        0        0        0        0        0   \n",
      "82019        0        0        0        0        0        0        0        0   \n",
      "82020        0        0        0        0        0        0        0        0   \n",
      "82021        0        0        0        0        0        0        0        0   \n",
      "82022        0        0        0        0        0        0        0        0   \n",
      "82023        0        0        0        0        0        0        0        0   \n",
      "82024        0        0        0        0        0        0        0        0   \n",
      "82025        0        0        0        0        0        0        0        0   \n",
      "82026        0        0        0        0        0        0        0        0   \n",
      "82027        0        0        0        0        0        0        0        0   \n",
      "82028        0        0        0        0        0        0        0        0   \n",
      "82029        0        0        0        0        0        0        0        0   \n",
      "82030        0        0        0        0        0        0        0        0   \n",
      "82031        0        0        0        0        0        0        0        0   \n",
      "82032        0        0        0        0        0        0        0        0   \n",
      "82033        0        0        0        0        0        0        0        0   \n",
      "82034        0        0        0        0        0        0        0        0   \n",
      "82035        0        0        0        0        0        0        0        0   \n",
      "\n",
      "       V156807  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "5            0  \n",
      "6            0  \n",
      "7            0  \n",
      "8            0  \n",
      "9            0  \n",
      "10           0  \n",
      "11           0  \n",
      "12           0  \n",
      "13           0  \n",
      "14           0  \n",
      "15           0  \n",
      "16           0  \n",
      "17           0  \n",
      "18           0  \n",
      "19           0  \n",
      "20           0  \n",
      "21           0  \n",
      "22           0  \n",
      "23           0  \n",
      "24           0  \n",
      "25           0  \n",
      "26           0  \n",
      "27           0  \n",
      "28           0  \n",
      "29           0  \n",
      "...        ...  \n",
      "82006        0  \n",
      "82007        0  \n",
      "82008        0  \n",
      "82009        0  \n",
      "82010        0  \n",
      "82011        0  \n",
      "82012        0  \n",
      "82013        0  \n",
      "82014        0  \n",
      "82015        0  \n",
      "82016        0  \n",
      "82017        0  \n",
      "82018        0  \n",
      "82019        0  \n",
      "82020        0  \n",
      "82021        0  \n",
      "82022        0  \n",
      "82023        0  \n",
      "82024        0  \n",
      "82025        0  \n",
      "82026        0  \n",
      "82027        0  \n",
      "82028        0  \n",
      "82029        0  \n",
      "82030        0  \n",
      "82031        0  \n",
      "82032        0  \n",
      "82033        0  \n",
      "82034        0  \n",
      "82035        0  \n",
      "\n",
      "[82036 rows x 196 columns]\n"
     ]
    }
   ],
   "source": [
    "# CURRENTLY NECESSARY IF: USING 174 ADDITIONAL VARIETY COLUMNS METHOD\n",
    "\n",
    "# THIS IS A DIFFERENT APPROACH TO THE ABOVE FOUR CELLS, WHERE WE HAVE 174 ADDITIONAL FEATURE COLUMNS\n",
    "# EACH WITH A 0 (IF IT IS NOT OF THAT VARIETY) OR A 1 (IF IT IS OF THAT VARIETY)\n",
    "\n",
    "# print(df)\n",
    "dummies = pd.get_dummies(df.Variety)\n",
    "# print(dummies)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment <class 'str'>\n",
      "Location <class 'numpy.int64'>\n",
      "Variety <class 'str'>\n",
      "Planting date <class 'str'>\n",
      "Yield <class 'numpy.float64'>\n",
      "Check Yield <class 'numpy.float64'>\n",
      "Yield difference <class 'numpy.float64'>\n",
      "Year <class 'numpy.int64'>\n",
      "Latitude <class 'numpy.float64'>\n",
      "Longitude <class 'numpy.float64'>\n",
      "Temperature <class 'numpy.float64'>\n",
      "Precipitation <class 'numpy.float64'>\n",
      "Solar Radiation <class 'numpy.int64'>\n",
      "Soil class <class 'numpy.int64'>\n",
      "CEC <class 'numpy.float64'>\n",
      "Organic matter <class 'numpy.float64'>\n",
      "pH <class 'numpy.float64'>\n",
      "Clay <class 'numpy.float64'>\n",
      "Silt <class 'numpy.float64'>\n",
      "Sand <class 'numpy.float64'>\n",
      "PI <class 'str'>\n",
      "Area <class 'numpy.float64'>\n",
      "V000016 <class 'numpy.uint8'>\n",
      "V000017 <class 'numpy.uint8'>\n",
      "V000018 <class 'numpy.uint8'>\n",
      "V000023 <class 'numpy.uint8'>\n",
      "V000024 <class 'numpy.uint8'>\n",
      "V000025 <class 'numpy.uint8'>\n",
      "V000030 <class 'numpy.uint8'>\n",
      "V000032 <class 'numpy.uint8'>\n",
      "V000034 <class 'numpy.uint8'>\n",
      "V000036 <class 'numpy.uint8'>\n",
      "V000039 <class 'numpy.uint8'>\n",
      "V000047 <class 'numpy.uint8'>\n",
      "V000050 <class 'numpy.uint8'>\n",
      "V000051 <class 'numpy.uint8'>\n",
      "V000058 <class 'numpy.uint8'>\n",
      "V000060 <class 'numpy.uint8'>\n",
      "V000062 <class 'numpy.uint8'>\n",
      "V000067 <class 'numpy.uint8'>\n",
      "V000070 <class 'numpy.uint8'>\n",
      "V000071 <class 'numpy.uint8'>\n",
      "V000075 <class 'numpy.uint8'>\n",
      "V000078 <class 'numpy.uint8'>\n",
      "V000079 <class 'numpy.uint8'>\n",
      "V000080 <class 'numpy.uint8'>\n",
      "V000081 <class 'numpy.uint8'>\n",
      "V000082 <class 'numpy.uint8'>\n",
      "V000092 <class 'numpy.uint8'>\n",
      "V000096 <class 'numpy.uint8'>\n",
      "V000098 <class 'numpy.uint8'>\n",
      "V000110 <class 'numpy.uint8'>\n",
      "V000115 <class 'numpy.uint8'>\n",
      "V000122 <class 'numpy.uint8'>\n",
      "V000123 <class 'numpy.uint8'>\n",
      "V000124 <class 'numpy.uint8'>\n",
      "V000125 <class 'numpy.uint8'>\n",
      "V000134 <class 'numpy.uint8'>\n",
      "V000147 <class 'numpy.uint8'>\n",
      "V000157 <class 'numpy.uint8'>\n",
      "V000172 <class 'numpy.uint8'>\n",
      "V000721 <class 'numpy.uint8'>\n",
      "V031243 <class 'numpy.uint8'>\n",
      "V051214 <class 'numpy.uint8'>\n",
      "V103132 <class 'numpy.uint8'>\n",
      "V103136 <class 'numpy.uint8'>\n",
      "V103139 <class 'numpy.uint8'>\n",
      "V103142 <class 'numpy.uint8'>\n",
      "V103150 <class 'numpy.uint8'>\n",
      "V103155 <class 'numpy.uint8'>\n",
      "V103156 <class 'numpy.uint8'>\n",
      "V103159 <class 'numpy.uint8'>\n",
      "V103163 <class 'numpy.uint8'>\n",
      "V103173 <class 'numpy.uint8'>\n",
      "V103193 <class 'numpy.uint8'>\n",
      "V103198 <class 'numpy.uint8'>\n",
      "V103259 <class 'numpy.uint8'>\n",
      "V103266 <class 'numpy.uint8'>\n",
      "V103273 <class 'numpy.uint8'>\n",
      "V103277 <class 'numpy.uint8'>\n",
      "V103281 <class 'numpy.uint8'>\n",
      "V103286 <class 'numpy.uint8'>\n",
      "V103293 <class 'numpy.uint8'>\n",
      "V103302 <class 'numpy.uint8'>\n",
      "V103303 <class 'numpy.uint8'>\n",
      "V103308 <class 'numpy.uint8'>\n",
      "V103332 <class 'numpy.uint8'>\n",
      "V103425 <class 'numpy.uint8'>\n",
      "V103466 <class 'numpy.uint8'>\n",
      "V103620 <class 'numpy.uint8'>\n",
      "V103624 <class 'numpy.uint8'>\n",
      "V103866 <class 'numpy.uint8'>\n",
      "V103970 <class 'numpy.uint8'>\n",
      "V104000 <class 'numpy.uint8'>\n",
      "V110768 <class 'numpy.uint8'>\n",
      "V110890 <class 'numpy.uint8'>\n",
      "V110923 <class 'numpy.uint8'>\n",
      "V111237 <class 'numpy.uint8'>\n",
      "V111336 <class 'numpy.uint8'>\n",
      "V113396 <class 'numpy.uint8'>\n",
      "V113424 <class 'numpy.uint8'>\n",
      "V113476 <class 'numpy.uint8'>\n",
      "V114530 <class 'numpy.uint8'>\n",
      "V114541 <class 'numpy.uint8'>\n",
      "V114545 <class 'numpy.uint8'>\n",
      "V114553 <class 'numpy.uint8'>\n",
      "V114564 <class 'numpy.uint8'>\n",
      "V114565 <class 'numpy.uint8'>\n",
      "V114655 <class 'numpy.uint8'>\n",
      "V114944 <class 'numpy.uint8'>\n",
      "V114951 <class 'numpy.uint8'>\n",
      "V119975 <class 'numpy.uint8'>\n",
      "V120038 <class 'numpy.uint8'>\n",
      "V120047 <class 'numpy.uint8'>\n",
      "V120246 <class 'numpy.uint8'>\n",
      "V120410 <class 'numpy.uint8'>\n",
      "V120585 <class 'numpy.uint8'>\n",
      "V120810 <class 'numpy.uint8'>\n",
      "V120912 <class 'numpy.uint8'>\n",
      "V120999 <class 'numpy.uint8'>\n",
      "V121015 <class 'numpy.uint8'>\n",
      "V121097 <class 'numpy.uint8'>\n",
      "V121140 <class 'numpy.uint8'>\n",
      "V121524 <class 'numpy.uint8'>\n",
      "V124343 <class 'numpy.uint8'>\n",
      "V130305 <class 'numpy.uint8'>\n",
      "V130307 <class 'numpy.uint8'>\n",
      "V130308 <class 'numpy.uint8'>\n",
      "V131675 <class 'numpy.uint8'>\n",
      "V131778 <class 'numpy.uint8'>\n",
      "V136868 <class 'numpy.uint8'>\n",
      "V137136 <class 'numpy.uint8'>\n",
      "V137147 <class 'numpy.uint8'>\n",
      "V137160 <class 'numpy.uint8'>\n",
      "V137237 <class 'numpy.uint8'>\n",
      "V137289 <class 'numpy.uint8'>\n",
      "V139094 <class 'numpy.uint8'>\n",
      "V139107 <class 'numpy.uint8'>\n",
      "V139548 <class 'numpy.uint8'>\n",
      "V140091 <class 'numpy.uint8'>\n",
      "V140364 <class 'numpy.uint8'>\n",
      "V140784 <class 'numpy.uint8'>\n",
      "V150834 <class 'numpy.uint8'>\n",
      "V150844 <class 'numpy.uint8'>\n",
      "V150847 <class 'numpy.uint8'>\n",
      "V150853 <class 'numpy.uint8'>\n",
      "V150974 <class 'numpy.uint8'>\n",
      "V151036 <class 'numpy.uint8'>\n",
      "V151236 <class 'numpy.uint8'>\n",
      "V151273 <class 'numpy.uint8'>\n",
      "V151284 <class 'numpy.uint8'>\n",
      "V151329 <class 'numpy.uint8'>\n",
      "V151331 <class 'numpy.uint8'>\n",
      "V151332 <class 'numpy.uint8'>\n",
      "V151333 <class 'numpy.uint8'>\n",
      "V151334 <class 'numpy.uint8'>\n",
      "V151336 <class 'numpy.uint8'>\n",
      "V151337 <class 'numpy.uint8'>\n",
      "V151340 <class 'numpy.uint8'>\n",
      "V151399 <class 'numpy.uint8'>\n",
      "V151407 <class 'numpy.uint8'>\n",
      "V152053 <class 'numpy.uint8'>\n",
      "V152061 <class 'numpy.uint8'>\n",
      "V152067 <class 'numpy.uint8'>\n",
      "V152079 <class 'numpy.uint8'>\n",
      "V152102 <class 'numpy.uint8'>\n",
      "V152253 <class 'numpy.uint8'>\n",
      "V152300 <class 'numpy.uint8'>\n",
      "V152312 <class 'numpy.uint8'>\n",
      "V152320 <class 'numpy.uint8'>\n",
      "V152322 <class 'numpy.uint8'>\n",
      "V152440 <class 'numpy.uint8'>\n",
      "V152734 <class 'numpy.uint8'>\n",
      "V152779 <class 'numpy.uint8'>\n",
      "V155180 <class 'numpy.uint8'>\n",
      "V155820 <class 'numpy.uint8'>\n",
      "V155842 <class 'numpy.uint8'>\n",
      "V155843 <class 'numpy.uint8'>\n",
      "V155918 <class 'numpy.uint8'>\n",
      "V156247 <class 'numpy.uint8'>\n",
      "V156305 <class 'numpy.uint8'>\n",
      "V156314 <class 'numpy.uint8'>\n",
      "V156367 <class 'numpy.uint8'>\n",
      "V156368 <class 'numpy.uint8'>\n",
      "V156516 <class 'numpy.uint8'>\n",
      "V156553 <class 'numpy.uint8'>\n",
      "V156565 <class 'numpy.uint8'>\n",
      "V156574 <class 'numpy.uint8'>\n",
      "V156642 <class 'numpy.uint8'>\n",
      "V156763 <class 'numpy.uint8'>\n",
      "V156774 <class 'numpy.uint8'>\n",
      "V156783 <class 'numpy.uint8'>\n",
      "V156786 <class 'numpy.uint8'>\n",
      "V156797 <class 'numpy.uint8'>\n",
      "V156806 <class 'numpy.uint8'>\n",
      "V156807 <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "# ORIGINAL COLUMNS! WE WANT TO PICK ONES THAT ARE GOOD FOR OUR LEARNING ALGORITHM AND DROP THE REST IN THE\n",
    "# FOLLOWING CELL\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col, type(df[col][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP ALL THE CELLS THAT ARE NOT USABLE SUCH AS THE ONES THAT ARE STRINGS OR DATES\n",
    "\n",
    "df = df.drop(['Experiment', 'Location', 'Planting date', 'Check Yield', 'Yield difference', 'Latitude', 'Longitude', 'Variety', 'PI'], axis=1)\n",
    "df['YieldBucket'] = pd.Series(pd.qcut(df.Yield, q=3, labels=[\"high\", \"medium\", \"low\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.YieldBucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We expect to be 0 nan values and there actually are 0 nan values\n",
      "\n",
      "Yield <class 'numpy.float64'>\n",
      "Year <class 'numpy.int64'>\n",
      "Temperature <class 'numpy.float64'>\n",
      "Precipitation <class 'numpy.float64'>\n",
      "Solar Radiation <class 'numpy.int64'>\n",
      "Soil class <class 'numpy.int64'>\n",
      "CEC <class 'numpy.float64'>\n",
      "Organic matter <class 'numpy.float64'>\n",
      "pH <class 'numpy.float64'>\n",
      "Clay <class 'numpy.float64'>\n",
      "Silt <class 'numpy.float64'>\n",
      "Sand <class 'numpy.float64'>\n",
      "Area <class 'numpy.float64'>\n",
      "V000016 <class 'numpy.uint8'>\n",
      "V000017 <class 'numpy.uint8'>\n",
      "V000018 <class 'numpy.uint8'>\n",
      "V000023 <class 'numpy.uint8'>\n",
      "V000024 <class 'numpy.uint8'>\n",
      "V000025 <class 'numpy.uint8'>\n",
      "V000030 <class 'numpy.uint8'>\n",
      "V000032 <class 'numpy.uint8'>\n",
      "V000034 <class 'numpy.uint8'>\n",
      "V000036 <class 'numpy.uint8'>\n",
      "V000039 <class 'numpy.uint8'>\n",
      "V000047 <class 'numpy.uint8'>\n",
      "V000050 <class 'numpy.uint8'>\n",
      "V000051 <class 'numpy.uint8'>\n",
      "V000058 <class 'numpy.uint8'>\n",
      "V000060 <class 'numpy.uint8'>\n",
      "V000062 <class 'numpy.uint8'>\n",
      "V000067 <class 'numpy.uint8'>\n",
      "V000070 <class 'numpy.uint8'>\n",
      "V000071 <class 'numpy.uint8'>\n",
      "V000075 <class 'numpy.uint8'>\n",
      "V000078 <class 'numpy.uint8'>\n",
      "V000079 <class 'numpy.uint8'>\n",
      "V000080 <class 'numpy.uint8'>\n",
      "V000081 <class 'numpy.uint8'>\n",
      "V000082 <class 'numpy.uint8'>\n",
      "V000092 <class 'numpy.uint8'>\n",
      "V000096 <class 'numpy.uint8'>\n",
      "V000098 <class 'numpy.uint8'>\n",
      "V000110 <class 'numpy.uint8'>\n",
      "V000115 <class 'numpy.uint8'>\n",
      "V000122 <class 'numpy.uint8'>\n",
      "V000123 <class 'numpy.uint8'>\n",
      "V000124 <class 'numpy.uint8'>\n",
      "V000125 <class 'numpy.uint8'>\n",
      "V000134 <class 'numpy.uint8'>\n",
      "V000147 <class 'numpy.uint8'>\n",
      "V000157 <class 'numpy.uint8'>\n",
      "V000172 <class 'numpy.uint8'>\n",
      "V000721 <class 'numpy.uint8'>\n",
      "V031243 <class 'numpy.uint8'>\n",
      "V051214 <class 'numpy.uint8'>\n",
      "V103132 <class 'numpy.uint8'>\n",
      "V103136 <class 'numpy.uint8'>\n",
      "V103139 <class 'numpy.uint8'>\n",
      "V103142 <class 'numpy.uint8'>\n",
      "V103150 <class 'numpy.uint8'>\n",
      "V103155 <class 'numpy.uint8'>\n",
      "V103156 <class 'numpy.uint8'>\n",
      "V103159 <class 'numpy.uint8'>\n",
      "V103163 <class 'numpy.uint8'>\n",
      "V103173 <class 'numpy.uint8'>\n",
      "V103193 <class 'numpy.uint8'>\n",
      "V103198 <class 'numpy.uint8'>\n",
      "V103259 <class 'numpy.uint8'>\n",
      "V103266 <class 'numpy.uint8'>\n",
      "V103273 <class 'numpy.uint8'>\n",
      "V103277 <class 'numpy.uint8'>\n",
      "V103281 <class 'numpy.uint8'>\n",
      "V103286 <class 'numpy.uint8'>\n",
      "V103293 <class 'numpy.uint8'>\n",
      "V103302 <class 'numpy.uint8'>\n",
      "V103303 <class 'numpy.uint8'>\n",
      "V103308 <class 'numpy.uint8'>\n",
      "V103332 <class 'numpy.uint8'>\n",
      "V103425 <class 'numpy.uint8'>\n",
      "V103466 <class 'numpy.uint8'>\n",
      "V103620 <class 'numpy.uint8'>\n",
      "V103624 <class 'numpy.uint8'>\n",
      "V103866 <class 'numpy.uint8'>\n",
      "V103970 <class 'numpy.uint8'>\n",
      "V104000 <class 'numpy.uint8'>\n",
      "V110768 <class 'numpy.uint8'>\n",
      "V110890 <class 'numpy.uint8'>\n",
      "V110923 <class 'numpy.uint8'>\n",
      "V111237 <class 'numpy.uint8'>\n",
      "V111336 <class 'numpy.uint8'>\n",
      "V113396 <class 'numpy.uint8'>\n",
      "V113424 <class 'numpy.uint8'>\n",
      "V113476 <class 'numpy.uint8'>\n",
      "V114530 <class 'numpy.uint8'>\n",
      "V114541 <class 'numpy.uint8'>\n",
      "V114545 <class 'numpy.uint8'>\n",
      "V114553 <class 'numpy.uint8'>\n",
      "V114564 <class 'numpy.uint8'>\n",
      "V114565 <class 'numpy.uint8'>\n",
      "V114655 <class 'numpy.uint8'>\n",
      "V114944 <class 'numpy.uint8'>\n",
      "V114951 <class 'numpy.uint8'>\n",
      "V119975 <class 'numpy.uint8'>\n",
      "V120038 <class 'numpy.uint8'>\n",
      "V120047 <class 'numpy.uint8'>\n",
      "V120246 <class 'numpy.uint8'>\n",
      "V120410 <class 'numpy.uint8'>\n",
      "V120585 <class 'numpy.uint8'>\n",
      "V120810 <class 'numpy.uint8'>\n",
      "V120912 <class 'numpy.uint8'>\n",
      "V120999 <class 'numpy.uint8'>\n",
      "V121015 <class 'numpy.uint8'>\n",
      "V121097 <class 'numpy.uint8'>\n",
      "V121140 <class 'numpy.uint8'>\n",
      "V121524 <class 'numpy.uint8'>\n",
      "V124343 <class 'numpy.uint8'>\n",
      "V130305 <class 'numpy.uint8'>\n",
      "V130307 <class 'numpy.uint8'>\n",
      "V130308 <class 'numpy.uint8'>\n",
      "V131675 <class 'numpy.uint8'>\n",
      "V131778 <class 'numpy.uint8'>\n",
      "V136868 <class 'numpy.uint8'>\n",
      "V137136 <class 'numpy.uint8'>\n",
      "V137147 <class 'numpy.uint8'>\n",
      "V137160 <class 'numpy.uint8'>\n",
      "V137237 <class 'numpy.uint8'>\n",
      "V137289 <class 'numpy.uint8'>\n",
      "V139094 <class 'numpy.uint8'>\n",
      "V139107 <class 'numpy.uint8'>\n",
      "V139548 <class 'numpy.uint8'>\n",
      "V140091 <class 'numpy.uint8'>\n",
      "V140364 <class 'numpy.uint8'>\n",
      "V140784 <class 'numpy.uint8'>\n",
      "V150834 <class 'numpy.uint8'>\n",
      "V150844 <class 'numpy.uint8'>\n",
      "V150847 <class 'numpy.uint8'>\n",
      "V150853 <class 'numpy.uint8'>\n",
      "V150974 <class 'numpy.uint8'>\n",
      "V151036 <class 'numpy.uint8'>\n",
      "V151236 <class 'numpy.uint8'>\n",
      "V151273 <class 'numpy.uint8'>\n",
      "V151284 <class 'numpy.uint8'>\n",
      "V151329 <class 'numpy.uint8'>\n",
      "V151331 <class 'numpy.uint8'>\n",
      "V151332 <class 'numpy.uint8'>\n",
      "V151333 <class 'numpy.uint8'>\n",
      "V151334 <class 'numpy.uint8'>\n",
      "V151336 <class 'numpy.uint8'>\n",
      "V151337 <class 'numpy.uint8'>\n",
      "V151340 <class 'numpy.uint8'>\n",
      "V151399 <class 'numpy.uint8'>\n",
      "V151407 <class 'numpy.uint8'>\n",
      "V152053 <class 'numpy.uint8'>\n",
      "V152061 <class 'numpy.uint8'>\n",
      "V152067 <class 'numpy.uint8'>\n",
      "V152079 <class 'numpy.uint8'>\n",
      "V152102 <class 'numpy.uint8'>\n",
      "V152253 <class 'numpy.uint8'>\n",
      "V152300 <class 'numpy.uint8'>\n",
      "V152312 <class 'numpy.uint8'>\n",
      "V152320 <class 'numpy.uint8'>\n",
      "V152322 <class 'numpy.uint8'>\n",
      "V152440 <class 'numpy.uint8'>\n",
      "V152734 <class 'numpy.uint8'>\n",
      "V152779 <class 'numpy.uint8'>\n",
      "V155180 <class 'numpy.uint8'>\n",
      "V155820 <class 'numpy.uint8'>\n",
      "V155842 <class 'numpy.uint8'>\n",
      "V155843 <class 'numpy.uint8'>\n",
      "V155918 <class 'numpy.uint8'>\n",
      "V156247 <class 'numpy.uint8'>\n",
      "V156305 <class 'numpy.uint8'>\n",
      "V156314 <class 'numpy.uint8'>\n",
      "V156367 <class 'numpy.uint8'>\n",
      "V156368 <class 'numpy.uint8'>\n",
      "V156516 <class 'numpy.uint8'>\n",
      "V156553 <class 'numpy.uint8'>\n",
      "V156565 <class 'numpy.uint8'>\n",
      "V156574 <class 'numpy.uint8'>\n",
      "V156642 <class 'numpy.uint8'>\n",
      "V156763 <class 'numpy.uint8'>\n",
      "V156774 <class 'numpy.uint8'>\n",
      "V156783 <class 'numpy.uint8'>\n",
      "V156786 <class 'numpy.uint8'>\n",
      "V156797 <class 'numpy.uint8'>\n",
      "V156806 <class 'numpy.uint8'>\n",
      "V156807 <class 'numpy.uint8'>\n",
      "YieldBucket <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# LET US ALSO MAKE SURE THERE ARE NO NAN IN THE DATA\n",
    "print(\"We expect to be %s nan values and there actually are %s nan values\\n\" % (0, np.sum(df.isnull().sum())))\n",
    "# AFTER COLUMNS, MAKE SURE NO SKETCHY ONES\n",
    "for col in df.columns:\n",
    "    print(col, type(df[col][0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Temperature', 'Precipitation', 'Solar Radiation', 'Soil class',\n",
      "       'CEC', 'Organic matter', 'pH', 'Clay', 'Silt',\n",
      "       ...\n",
      "       'V156565', 'V156574', 'V156642', 'V156763', 'V156774', 'V156783',\n",
      "       'V156786', 'V156797', 'V156806', 'V156807'],\n",
      "      dtype='object', length=186)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "\n",
    "# feature_columns = ['Variety', 'Solar Radiation', 'Temperature', 'Precipitation', 'Location', 'Clay', 'Silt', 'Sand', 'pH', 'Precipitation', 'CEC', 'Soil class']\n",
    "\n",
    "X = df.drop(['Yield', 'YieldBucket'], axis=1)\n",
    "\n",
    "print(X.columns)\n",
    "# X = df.loc[:, feature_columns]\n",
    "\n",
    "y = df.Yield\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, train_size = 0.1, random_state = 42)\n",
    "\n",
    "# train_visual, zz, zzz, zzzz = train_test_split(df, y, test_size=0.2, train_size=0.8, random_state = 42)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scalar = StandardScaler()\n",
    "x_std = standard_scalar.fit_transform(X_train)\n",
    "print(x_std.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0, verbose=1)\n",
    "x_2d = tsne.fit_transform(x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_2d.shape)\n",
    "print(x_2d)\n",
    "from matplotlib import pyplot as plt\n",
    "markers=('s', 'd', 'o', '^', 'v')\n",
    "color_map = {0:'red', 1:'blue', 2:'lightgreen', 3:'purple', 4:'cyan'}\n",
    "plt.figure()\n",
    "# for idx, cl in enumerate(np.unique(x_2d)):\n",
    "#     print(cl)\n",
    "for idx, cl in enumerate(np.unique(y_train)):\n",
    "    plt.scatter(x=x_2d[y_train==cl,0], y=x_2d[y_train==cl,1], c=color_map[idx], marker=markers[idx], label=cl)\n",
    "\n",
    "#     plt.scatter(x=x_2d[cl,0], y=x_2d[cl,1], c=color_map[idx], marker=markers[idx], label=cl)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE FEATURE DISTRIBUTIONS OPTIONALLY\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "X_train[X_train.dtypes[(X_train.dtypes==\"float64\")|(X_train.dtypes==\"int64\")]\n",
    "                        .index.values].hist(figsize=[11,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT COULDN'T HURT TO SEE THE FINAL SHAPES\n",
    "\n",
    "# print(X_train.describe())\n",
    "print(X_train.head())\n",
    "# print(y_train.describe())\n",
    "print(y_train.head())\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76141    10.877733\n",
      "11321    32.027218\n",
      "68096     3.732009\n",
      "10813     7.083996\n",
      "30586    13.099676\n",
      "62263     0.169935\n",
      "58403    14.902803\n",
      "45601    22.641332\n",
      "69170    12.180727\n",
      "20865     1.075812\n",
      "14592    22.721368\n",
      "79035     0.802202\n",
      "48667     9.250887\n",
      "31714     5.923314\n",
      "48739     0.008617\n",
      "73832     9.469397\n",
      "38065    13.972367\n",
      "17050    16.761505\n",
      "61447     8.600825\n",
      "9293      3.060658\n",
      "64269     2.380120\n",
      "50211     0.981352\n",
      "15219     2.729307\n",
      "43234    12.170631\n",
      "60842     1.982009\n",
      "33703     3.836347\n",
      "40339     5.194961\n",
      "78791    16.699990\n",
      "54940    12.182294\n",
      "32595     5.406208\n",
      "           ...    \n",
      "47740     7.615550\n",
      "35395     4.528425\n",
      "54690    17.637905\n",
      "58371     8.219257\n",
      "41131     6.978146\n",
      "48939     6.247113\n",
      "71954     1.233109\n",
      "80128     3.196335\n",
      "23210     0.826165\n",
      "59380     8.503543\n",
      "49343     4.515253\n",
      "75084     2.974517\n",
      "3821      1.782477\n",
      "27294    16.825041\n",
      "56009    11.779612\n",
      "8107      2.378736\n",
      "4086      1.811456\n",
      "2522     17.918008\n",
      "81788     4.998064\n",
      "3024      8.930440\n",
      "71351    11.169764\n",
      "16141    21.586555\n",
      "74593     7.397310\n",
      "25983    21.316887\n",
      "12450    10.174708\n",
      "24760     4.074070\n",
      "16370    10.494063\n",
      "52472     2.825936\n",
      "37028    25.531165\n",
      "20546    33.586300\n",
      "Name: Yield, Length: 4102, dtype: float64\n",
      "10.005838207423524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=0, verbose=1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "errors = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "# erros = \n",
    "print(errors)\n",
    "print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WILL ONLY WORK WITH THE BUCKET METHOD\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "regr = RandomForestClassifier(n_estimators=10, max_depth=20, random_state=0, verbose=1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET OUTPUT OF FEATURE IMPORTANCE\n",
    "\n",
    "feature_importances = regr.feature_importances_\n",
    "feature_importances = pd.Series(feature_importances)\n",
    "feature_importance_df = pd.DataFrame({'feature': X_train.columns,'feature_importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by=['feature_importance'])\n",
    "for index, row in feature_importance_df.iterrows():\n",
    "    print(row['feature'], 'has importance: ', row['feature_importance'])\n",
    "# for feature_importance in regr.feature_importances_:\n",
    "    \n",
    "print(errors.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "classifiers = [\n",
    "    svm.SVR(),\n",
    "    MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=1),\n",
    "#     linear_model.SGDRegressor(),\n",
    "#     linear_model.BayesianRidge(),\n",
    "#     linear_model.LassoLars(),\n",
    "#     linear_model.ARDRegression(),\n",
    "#     linear_model.ARDRegression(),\n",
    "    linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.TheilSenRegressor(),\n",
    "    linear_model.LinearRegression()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# estimator = svm.SVR(kernel=\"linear\")\n",
    "\n",
    "# selector = RFECV(estimator, step=1, cv=5, verbose=1)\n",
    "# selector = selector.fit(X_train, y_train)\n",
    "# selector.support_ \n",
    "# # array([ True,  True,  True,  True,  True,\n",
    "# #         False, False, False, False, False], dtype=bool)\n",
    "# selector.ranking_\n",
    "# # array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])\n",
    "\n",
    "\n",
    "#     print(np.sum(preds - y_test))\n",
    "#     print(clf.predict(X_test),'\\n')\n",
    "#     print(y_test)\n",
    "#     print('accuracy score:', accuracy_score(y_test, clf.predict(X_test)), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    errors = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "    print(errors)\n",
    "    print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import tree\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#     DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "from sklearn.metrics import accuracy_score\n",
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, preds))\n",
    "#     errors = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "#     print(errors)\n",
    "#     print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima price dataset\n",
    "dataset = datasets.load_boston()\n",
    "# split into input (X) and output (Y) variables\n",
    "# X = dataset[:,0:8]\n",
    "# Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Compile model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, y_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# # convert an array of values into a dataset matrix\n",
    "# def create_dataset(dataset, look_back=1):\n",
    "# \tdataX, dataY = [], []\n",
    "# \tfor i in range(len(dataset)-look_back-1):\n",
    "# \t\ta = dataset[i:(i+look_back), 0]\n",
    "# \t\tdataX.append(a)\n",
    "# \t\tdataY.append(dataset[i + look_back, 0])\n",
    "# \treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# # fix random seed for reproducibility\n",
    "# numpy.random.seed(7)\n",
    "# # load the dataset\n",
    "# # dataframe = read_csv('Syngenta/Syngenta_2017/Experiment_dataset.csv', engine='python', skipfooter=3)\n",
    "# dataset = dataframe.values\n",
    "# dataset = dataset.astype('float32')\n",
    "# # normalize the dataset\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# dataset = scaler.fit_transform(dataset)\n",
    "# # split into train and test sets\n",
    "# train_size = int(len(dataset) * 0.67)\n",
    "# test_size = len(dataset) - train_size\n",
    "# train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# # reshape into X=t and Y=t+1\n",
    "look_back = 12\n",
    "# trainX, trainY = create_dataset(train, look_back)\n",
    "# testX, testY = create_dataset(test, look_back)\n",
    "# # reshape input to be [samples, time steps, features]\n",
    "# trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "# testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(8203, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(X_train)\n",
    "testPredict = model.predict(X_test)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
