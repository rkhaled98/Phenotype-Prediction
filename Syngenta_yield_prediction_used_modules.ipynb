{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THERE ARE SEPARATE NOTEBOOKS FOR VISUALIZATIONS, DATASET ANALYSIS, ETC. IN THE REPO.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# READ THE CSV INTO DATAFRAME\n",
    "\n",
    "df = pd.read_csv('Syngenta/Syngenta_2017/Experiment_dataset.csv')\n",
    "\n",
    "df_sf = pd.read_csv('Smart_Farm_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS USED WHEN CONNECTING TO COMPUTE NODES TO CHECK IF EVERYTHING IS WORKING\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY NECESSARY IF: USING 174 ADDITIONAL VARIETY COLUMNS METHOD\n",
    "\n",
    "variety_dummies = pd.get_dummies(df.Variety)\n",
    "df = pd.concat([df, variety_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY NECESSARY IF: USING 8 ADDITIONAL VARIETY COLUMNS (BINARY REPRESENTATION)\n",
    "\n",
    "UNIQUE_VARIETIES = np.unique(df.Variety)\n",
    "INDICES = [i for i in range(0, len(UNIQUE_VARIETIES))]\n",
    "print(np.where(UNIQUE_VARIETIES=='V000017'))\n",
    "df.Variety = df.Variety.apply(lambda var: np.where(UNIQUE_VARIETIES==var)[0][0])\n",
    "print(UNIQUE_VARIETIES)\n",
    "print(df.Variety)\n",
    "\n",
    "df.Variety = df.Variety.apply(lambda var: '{0:08b}'.format(var))\n",
    "print(\"done\")\n",
    "df.Variety = df.Variety.apply(lambda var: list(var))\n",
    "print(\"done\")\n",
    "variety_binary_df = pd.DataFrame(pd.Series(df.Variety[i]) for i in range(0, len(df.Variety)))\n",
    "df = pd.concat([df, variety_binary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GOAL OF THIS MODULE:\n",
    "# Encode the planting date as a season\n",
    "# NEW GOAL:\n",
    "# GET DUMMIES FOR SEASONS\n",
    "\n",
    "# remove the dates that are \".\"\n",
    "df = df[~df['Planting date'].str.match(\"\\.\")]\n",
    "plant_date = df['Planting date'].apply(lambda dt: pd.to_datetime(dt))\n",
    "plant_months = plant_date.apply(lambda dt: dt.month)\n",
    "season = plant_date.rename(\"Season\")\n",
    "season = pd.to_datetime(season)\n",
    "season = season.apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# df['Plant date'] = pd.to_datetime(df['Plant date'])\n",
    "df = pd.concat([df, season], axis=1)\n",
    "\n",
    "# plant_date = pd.to_datetime(df['Planting date'], infer_datetime_format=True)\n",
    "# df = df['Planting date'].apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# pd.get_dummies(df['Planting date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD MONTH OF MAY AND JUNE ONE HOT ENCODING INTO THE DATAFRAME\n",
    "pd.get_dummies(plant_months).sum()\n",
    "june = pd.get_dummies(plant_months).loc[:,6]\n",
    "june = june.rename(\"June\")\n",
    "may = pd.get_dummies(plant_months).loc[:,5]\n",
    "may = may.rename(\"May\")\n",
    "df = pd.concat([df, may], axis=1)\n",
    "df = pd.concat([df, june], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LATITUDE AND LONGITUDE CLUSTERING INTO FEATURES\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "latlong = df.loc[:, ['Latitude', 'Longitude']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(latlong)\n",
    "kmeans.labels_.shape\n",
    "lat_long_dummies = pd.get_dummies(kmeans.labels_)\n",
    "lat_long_dummies = lat_long_dummies.rename(index=int, columns={0: \"Loc Clust 0\",\n",
    "                                                               1: \"Loc Clust 1\",\n",
    "                                                               2: \"Loc Clust 2\",\n",
    "                                                               3: \"Loc Clust 3\"})\n",
    "df = pd.concat([df, lat_long_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Experiment', 'Location', 'Variety', 'Planting date', 'Yield',\n",
      "       'Check Yield', 'Yield difference', 'Year', 'Latitude', 'Longitude',\n",
      "       'Temperature', 'Precipitation', 'Solar Radiation', 'Soil class', 'CEC',\n",
      "       'Organic matter', 'pH', 'Clay', 'Silt', 'Sand', 'PI', 'Area', 'Season',\n",
      "       'May', 'June', 'Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2',\n",
      "       'Loc Clust 3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#REMOVE ANY NAN VALUES\n",
    "\n",
    "print(df.columns)\n",
    "df = df[~df.Silt.isnull()]\n",
    "df = df[~df['Loc Clust 1'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col, type(df[col][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final dataframe has columns:  Index(['Yield', 'Year', 'Temperature', 'Precipitation', 'Solar Radiation',\n",
      "       'Soil class', 'CEC', 'Organic matter', 'pH', 'Clay', 'Silt', 'Sand',\n",
      "       'Area', 'May', 'June', 'Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2',\n",
      "       'Loc Clust 3', 'YieldBucket'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# DROP ALL THE CELLS THAT ARE NOT USABLE SUCH AS THE ONES THAT ARE STRINGS OR DATES\n",
    "\n",
    "# set if want to drop some columns specifically\n",
    "should_drop = 1\n",
    "columns_to_drop = ['Experiment', 'Location',\n",
    "                   'Check Yield', 'Yield difference', 'Latitude',\n",
    "                   'Longitude', 'PI', 'Variety', 'Planting date', 'Season']\n",
    "\n",
    "# set if want to keep some columns specifically\n",
    "should_keep = 0\n",
    "# columns_to_keep = ['Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2', 'Loc Clust 3']\n",
    "columns_to_keep_top = ['Silt', 'Precipitation', 'Temperature', 'Solar Radiation', 'Organic matter']\n",
    "columns_VARIETIES_ONLY = np.asarray(df.iloc[:, df.columns.str.match('V\\d\\d\\d\\d\\d\\d')].columns)\n",
    "\n",
    "#set the below variable to whatever columns you want to keep\n",
    "columns_to_keep = columns_to_keep_top\n",
    "\n",
    "MUST_HAVE_COLUMNS = ['Yield']\n",
    "# print(columns_to_keep)\n",
    "\n",
    "df = df.drop(columns_to_drop, axis=1) if should_drop else df\n",
    "df = df.loc[:, np.concatenate((columns_to_keep, MUST_HAVE_COLUMNS))] if should_keep else df\n",
    "df['YieldBucket'] = pd.Series(pd.qcut(df.Yield, q=3, labels=[\"high\", \"medium\", \"low\"]))\n",
    "print(\"The final dataframe has columns: \", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LET US ALSO MAKE SURE THERE ARE NO NAN IN THE DATA\n",
    "print(\"We expect to be %s nan values and there actually are %s nan values\\n\" % (0, np.sum(df.isnull().sum())))\n",
    "print(df.isnull().sum())\n",
    "# AFTER COLUMNS, MAKE SURE NO SKETCHY ONES\n",
    "for col in df.columns:\n",
    "    print(col, type(df[col][0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Temperature', 'Precipitation', 'Solar Radiation', 'Soil class',\n",
      "       'CEC', 'Organic matter', 'pH', 'Clay', 'Silt', 'Sand', 'Area', 'May',\n",
      "       'June', 'Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2', 'Loc Clust 3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "\n",
    "X = df.drop(['Yield', 'YieldBucket'], axis=1)\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "y = df.Yield\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, train_size = 0.1, random_state = 42)\n",
    "\n",
    "INPUT_COLS = X_train.columns\n",
    "# TEST_COLS = y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7813, 18) \n",
      "y_train shape: (7813,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape, \"\\ny_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will evaluate the errors based on RMSE (from the challenge spec)\n",
    "# also will evaluate based on average error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def evaluate_errors(prediction, actual):\n",
    "    print(\"RMSE Error: \", np.sqrt(mean_squared_error(prediction, actual)))\n",
    "    avg_error_vector = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "#     print(\"Average Error: \", np.mean(avg_error_vector))\n",
    "    print(\"Average Error details:\\n\", avg_error_vector.describe())\n",
    "    return avg_error_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(n_estimators=1000, learning_rate=0.01)\n",
    "clf.fit(X_train, np.log1p(y_train))\n",
    "preds = np.expm1(clf.predict(X_test))\n",
    "evaluate_errors(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Error:  7.404785186969437\n",
      "Average Error details:\n",
      " count    3907.000000\n",
      "mean       10.565774\n",
      "std        11.455470\n",
      "min         0.002280\n",
      "25%         3.511498\n",
      "50%         7.616182\n",
      "75%        13.677386\n",
      "max       197.281042\n",
      "Name: Yield, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37747     3.023815\n",
       "34960     7.198115\n",
       "77631     2.825352\n",
       "29678     3.136440\n",
       "58370     3.685283\n",
       "44709     6.386415\n",
       "37353     2.379666\n",
       "11083    11.007744\n",
       "65678     9.156382\n",
       "68237     7.646327\n",
       "69975    12.573523\n",
       "53136     4.921622\n",
       "25669    29.577871\n",
       "22055     6.077461\n",
       "53416     2.523629\n",
       "1165     20.627535\n",
       "21660    27.801441\n",
       "10943    17.636145\n",
       "29486     3.421652\n",
       "73128     3.995045\n",
       "77434    10.938201\n",
       "74450     7.009889\n",
       "29534     5.777550\n",
       "79136     4.183589\n",
       "51908     5.548448\n",
       "6382      7.391764\n",
       "4497     11.379614\n",
       "29180     8.188265\n",
       "40968    14.865222\n",
       "56236     5.234357\n",
       "           ...    \n",
       "55268     9.446306\n",
       "36424     8.963997\n",
       "38873     0.661564\n",
       "53108     3.203873\n",
       "57176     7.309249\n",
       "9969      3.859484\n",
       "63588     2.630800\n",
       "53502    12.020692\n",
       "45568     6.506807\n",
       "5098     14.526325\n",
       "27685    22.412765\n",
       "19609    64.562177\n",
       "31942    10.804728\n",
       "3338     11.334763\n",
       "62444    10.501975\n",
       "67291     2.332348\n",
       "47450     9.549224\n",
       "11728     8.788222\n",
       "3337     14.216159\n",
       "49107    12.372128\n",
       "19969    20.919254\n",
       "55298    12.126365\n",
       "52721     7.850279\n",
       "15185    13.705117\n",
       "31732     8.102342\n",
       "78093    13.025233\n",
       "53280     1.460203\n",
       "63604    20.886309\n",
       "41242     2.736085\n",
       "19341     4.221188\n",
       "Name: Yield, Length: 3907, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(n_estimators=20, max_depth=13, random_state=0, verbose=1, n_jobs=-1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "evaluate_errors(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loc Clust 0 has importance:  0.012890156488064467\n",
      "Loc Clust 3 has importance:  0.013915496293010268\n",
      "Loc Clust 2 has importance:  0.013996485973801556\n",
      "Loc Clust 1 has importance:  0.014975083610222286\n",
      "Soil class has importance:  0.016145004016204077\n",
      "June has importance:  0.018097253354624993\n",
      "May has importance:  0.021369949647420936\n",
      "Clay has importance:  0.03787393818991075\n",
      "Sand has importance:  0.046254055263236775\n",
      "pH has importance:  0.05433367033485603\n",
      "CEC has importance:  0.055163539144148774\n",
      "Area has importance:  0.06412638830101888\n",
      "Solar Radiation has importance:  0.08059789601140775\n",
      "Temperature has importance:  0.08516317710895183\n",
      "Year has importance:  0.08614454802498779\n",
      "Organic matter has importance:  0.09373563257912265\n",
      "Precipitation has importance:  0.11336476020901129\n",
      "Silt has importance:  0.1718529654499989\n"
     ]
    }
   ],
   "source": [
    "# GET OUTPUT OF FEATURE IMPORTANCE\n",
    "def get_feature_importances(regr):\n",
    "    feature_importances = regr.feature_importances_\n",
    "    feature_importances = pd.Series(feature_importances)\n",
    "    feature_importance_df = pd.DataFrame({'feature': X_train.columns,'feature_importance': feature_importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by=['feature_importance'])\n",
    "    for index, row in feature_importance_df.iterrows():\n",
    "        print(row['feature'], 'has importance: ', row['feature_importance'])\n",
    "get_feature_importances(regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "#     MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "#                      hidden_layer_sizes=(5, 2), random_state=1),\n",
    "#     RandomForestRegressor(n_estimators=20, max_depth=13, random_state=0, verbose=1, n_jobs=-1),\n",
    "#     linear_model.SGDRegressor(),\n",
    "#     linear_model.BayesianRidge(),\n",
    "#     linear_model.LassoLars(),\n",
    "#     linear_model.ARDRegression(),\n",
    "#     linear_model.PassiveAggressiveRegressor(),\n",
    "#     linear_model.TheilSenRegressor(),\n",
    "#     linear_model.LinearRegression(),\n",
    "    svm.SVR(kernel=\"linear\"),\n",
    "    linear_model.ARDRegression()]\n",
    "\n",
    "# estimator = svm.SVR(kernel=\"linear\")\n",
    "# estimator = \n",
    "\n",
    "# selector = RFECV(estimator, step=1, cv=5, verbose=1, n_jobs=-1)\n",
    "# selector = selector.fit(X_train, y_train)\n",
    "# selector.support_ \n",
    "# # array([ True,  True,  True,  True,  True,\n",
    "# #         False, False, False, False, False], dtype=bool)\n",
    "# selector.ranking_\n",
    "# # array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])\n",
    "\n",
    "\n",
    "#     print(np.sum(preds - y_test))\n",
    "#     print(clf.predict(X_test),'\\n')\n",
    "#     print(y_test)\n",
    "#     print('accuracy score:', accuracy_score(y_test, clf.predict(X_test)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    selector = selector = RFECV(clf, step=1, verbose=1, n_jobs=-1)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    print(selector.support_)\n",
    "    print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_COLS = X_train.columns\n",
    "\n",
    "outputs = \"1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\"\n",
    "[ 4 10  9 11  8  7  3  2  1  1  1  1  1  5  6  1]\n",
    "import re\n",
    "outputs = re.sub(r'\\n', '', outputs)\n",
    "outputs = re.sub(r'  ', ' ', outputs)\n",
    "outputs = re.sub(r' ', ',', outputs)\n",
    "# print(outputs)\n",
    "\n",
    "# outputs.replace('\\n', \"\")\n",
    "# outputs.replace(\"  \", \",\")\n",
    "output = np.asarray(outputs.split(','))\n",
    "print(output)\n",
    "output = output == \"1\"\n",
    "\n",
    "for i in range(0, len(output)):\n",
    "    if output[i] == True:\n",
    "        print(\"CHOSEN: \", INPUT_COLS[i])\n",
    "    else:\n",
    "        print(\"NOT CHOSEN: ,\", INPUT_COLS[i])\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "errors = evaluate_errors(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    errors = evaluate_errors(preds, y_test)\n",
    "    try:\n",
    "        get_feature_importances(clf)\n",
    "    except:\n",
    "        print(\"NO FEATURE IMPORTANCE METRIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WILL ONLY WORK WITH THE BUCKET METHOD\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "regr = RandomForestClassifier(n_estimators=10, max_depth=20, random_state=0, verbose=1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#     DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "from sklearn.metrics import accuracy_score\n",
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(scale(X_train), y_train)\n",
    "    preds = clf.predict(scale(X_test))\n",
    "    print(accuracy_score(y_test, preds))\n",
    "#     errors = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "#     print(errors)\n",
    "#     print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "NUM_VARIETIES = 174\n",
    "\n",
    "def best_yield_variety(regr, test_set, random_sel = True, n_samples = 174, print_variety_preds = True):\n",
    "    \n",
    "    #create empty df\n",
    "    dup_df = pd.DataFrame()\n",
    "    \n",
    "    #choose a rand sample of input test_set (for dev purposes, wouldn't be used in app)\n",
    "    test_set_sample = test_set.sample(n= n_samples) if random_sel else test_set\n",
    "    \n",
    "    #progress of intensive, long for loop upcoming\n",
    "    counter = 0\n",
    "    \n",
    "    #for loop will, for each row in test_set_sample, duplicate that row by NUM_VARIETIES\n",
    "    for index, row in test_set_sample.iterrows():\n",
    "        counter+=1\n",
    "        print(counter)\n",
    "        dup_df = dup_df.append([row] * NUM_VARIETIES, ignore_index = True)\n",
    "        \n",
    "    #extract the varieties columns\n",
    "    duplicated_df_varieties = dup_df.loc[:, dup_df.columns.str.match('V\\d\\d\\d\\d\\d\\d')]\n",
    "    #extract the names of the varieties\n",
    "    varieties_array = duplicated_df_varieties.columns\n",
    "    num_expanded_data_pts = duplicated_df_varieties.shape[0]\n",
    "    #we must have a zeroed matrix of the same shape as the duplicated_df_varieties\n",
    "    #so that we can input a 1 just once for each variety per 174 rows\n",
    "    d = np.zeros((duplicated_df_varieties.shape[0], NUM_VARIETIES))\n",
    "    #make d our dataframe, with columns equal to the varieties\n",
    "    duplicated_df_varieties = pd.DataFrame(d, columns=varieties_array)\n",
    "    #for loop will place a 1 just once for each variety per 174 rows (one hot rep)\n",
    "    for i in range(duplicated_df_varieties.shape[0]):\n",
    "        var_index = i % 174\n",
    "        duplicated_df_varieties.loc[i, varieties_array[var_index]] = 1\n",
    "    #remove the varieties (will be added back with the new values)\n",
    "    dup_df = dup_df.drop(varieties_array, axis = 1)\n",
    "    #add the new values (one hot representations) from above for loop\n",
    "    dup_df = pd.concat([dup_df, duplicated_df_varieties], axis=1)\n",
    "    #do prediction on the entire dataframe\n",
    "    preds_per_variety = regr.predict(dup_df)\n",
    "    #*******make it into a dataframe where each row will give the performance of each variety\n",
    "    #with the same environmental conditions*******\n",
    "    preds_df = pd.DataFrame(preds_per_variety.reshape((int(num_expanded_data_pts/NUM_VARIETIES), NUM_VARIETIES)),\n",
    "                            columns=varieties_array)\n",
    "    \n",
    "    #environmental conditions (everything except the variety data)\n",
    "    envcond = test_set_sample.drop(varieties_array, axis=1)\n",
    "    \n",
    "    #a simple print out for best variety given the environmental conditions\n",
    "    hr_preds = []\n",
    "    if print_variety_preds:\n",
    "        envcond_cols = envcond.columns\n",
    "        counter = -1\n",
    "        for idx, row in envcond.iterrows():\n",
    "            counter+=1\n",
    "            out = \"For environmental conditions:\\n%s\\nthe best variety is:%s\" % (row, preds_df.idxmax(axis=1)[counter])\n",
    "            hr_preds.append(out)\n",
    "            print(out)\n",
    "    \n",
    "    return preds_df, envcond, hr_preds\n",
    "    \n",
    "        \n",
    "preds_df, envcond, hr_preds = best_yield_variety(regr, X_test, n_samples = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of times a variety is the maximum in the above prediction dataframe\n",
    "maxes = preds_df.idxmax(axis=1) # get first max variety per env\n",
    "# print(pd.get_dummies(maxes).describe())\n",
    "print(pd.get_dummies(maxes).sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of times a variety is the maximum in the above prediction dataframe\n",
    "maxes = preds_df.idxmax(axis=1) # get first max variety per env\n",
    "# print(pd.get_dummies(maxes).describe())\n",
    "print(pd.get_dummies(maxes).sum().sort_values(ascending=False))\n",
    "print(len(pd.get_dummies(maxes).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hr_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.describe().sort_values(by=\"mean\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.describe().loc['mean',:].sort_values().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> df = pd.DataFrame({\n",
    "...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
    "...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
    "...     }, index= ['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
    ">>> hist = df.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf = pd.concat([df_sf, pd.get_dummies(df_sf['Loc'])], axis=1)\n",
    "df_sf = pd.concat([df_sf, pd.get_dummies(df_sf['Gen'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAP</th>\n",
       "      <th>Gen</th>\n",
       "      <th>Loc</th>\n",
       "      <th>PlantID</th>\n",
       "      <th>Date</th>\n",
       "      <th>GrowthRate</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Solar.Rad</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/4/16</td>\n",
       "      <td>0.035015</td>\n",
       "      <td>67</td>\n",
       "      <td>22.28</td>\n",
       "      <td>52.82</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/5/16</td>\n",
       "      <td>0.038041</td>\n",
       "      <td>77</td>\n",
       "      <td>22.32</td>\n",
       "      <td>60.94</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/6/16</td>\n",
       "      <td>0.041329</td>\n",
       "      <td>83</td>\n",
       "      <td>26.10</td>\n",
       "      <td>81.27</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/7/16</td>\n",
       "      <td>0.044901</td>\n",
       "      <td>85</td>\n",
       "      <td>23.08</td>\n",
       "      <td>65.71</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/8/16</td>\n",
       "      <td>0.048783</td>\n",
       "      <td>85</td>\n",
       "      <td>22.64</td>\n",
       "      <td>62.41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>0.052999</td>\n",
       "      <td>81</td>\n",
       "      <td>20.30</td>\n",
       "      <td>47.66</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/10/16</td>\n",
       "      <td>0.057580</td>\n",
       "      <td>76</td>\n",
       "      <td>21.31</td>\n",
       "      <td>47.93</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/11/16</td>\n",
       "      <td>0.062557</td>\n",
       "      <td>87</td>\n",
       "      <td>22.32</td>\n",
       "      <td>49.38</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/12/16</td>\n",
       "      <td>0.067964</td>\n",
       "      <td>72</td>\n",
       "      <td>23.33</td>\n",
       "      <td>67.23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/13/16</td>\n",
       "      <td>0.073839</td>\n",
       "      <td>75</td>\n",
       "      <td>25.09</td>\n",
       "      <td>83.94</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/14/16</td>\n",
       "      <td>0.080221</td>\n",
       "      <td>81</td>\n",
       "      <td>20.38</td>\n",
       "      <td>64.41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/15/16</td>\n",
       "      <td>0.087155</td>\n",
       "      <td>57</td>\n",
       "      <td>19.15</td>\n",
       "      <td>52.71</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/16/16</td>\n",
       "      <td>0.094688</td>\n",
       "      <td>61</td>\n",
       "      <td>21.85</td>\n",
       "      <td>52.64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/17/16</td>\n",
       "      <td>0.102872</td>\n",
       "      <td>57</td>\n",
       "      <td>22.79</td>\n",
       "      <td>66.06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/18/16</td>\n",
       "      <td>0.111764</td>\n",
       "      <td>58</td>\n",
       "      <td>22.18</td>\n",
       "      <td>65.08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/19/16</td>\n",
       "      <td>0.121424</td>\n",
       "      <td>65</td>\n",
       "      <td>21.64</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/20/16</td>\n",
       "      <td>0.131920</td>\n",
       "      <td>64</td>\n",
       "      <td>24.88</td>\n",
       "      <td>83.16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/21/16</td>\n",
       "      <td>0.143322</td>\n",
       "      <td>72</td>\n",
       "      <td>23.80</td>\n",
       "      <td>64.87</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/22/16</td>\n",
       "      <td>0.155710</td>\n",
       "      <td>85</td>\n",
       "      <td>23.40</td>\n",
       "      <td>71.21</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/23/16</td>\n",
       "      <td>0.169169</td>\n",
       "      <td>87</td>\n",
       "      <td>19.22</td>\n",
       "      <td>52.67</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/24/16</td>\n",
       "      <td>0.183791</td>\n",
       "      <td>84</td>\n",
       "      <td>22.64</td>\n",
       "      <td>56.57</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/25/16</td>\n",
       "      <td>0.199677</td>\n",
       "      <td>93</td>\n",
       "      <td>24.52</td>\n",
       "      <td>74.88</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/26/16</td>\n",
       "      <td>0.216936</td>\n",
       "      <td>93</td>\n",
       "      <td>24.08</td>\n",
       "      <td>76.57</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/27/16</td>\n",
       "      <td>0.235687</td>\n",
       "      <td>88</td>\n",
       "      <td>24.08</td>\n",
       "      <td>69.32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/28/16</td>\n",
       "      <td>0.256059</td>\n",
       "      <td>77</td>\n",
       "      <td>23.72</td>\n",
       "      <td>67.65</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/29/16</td>\n",
       "      <td>0.278191</td>\n",
       "      <td>81</td>\n",
       "      <td>22.64</td>\n",
       "      <td>62.15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/30/16</td>\n",
       "      <td>0.302237</td>\n",
       "      <td>86</td>\n",
       "      <td>25.45</td>\n",
       "      <td>72.08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>5/31/16</td>\n",
       "      <td>0.328360</td>\n",
       "      <td>87</td>\n",
       "      <td>26.68</td>\n",
       "      <td>78.11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>6/1/16</td>\n",
       "      <td>0.356742</td>\n",
       "      <td>75</td>\n",
       "      <td>26.24</td>\n",
       "      <td>82.57</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>6/2/16</td>\n",
       "      <td>0.387577</td>\n",
       "      <td>75</td>\n",
       "      <td>21.85</td>\n",
       "      <td>61.87</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>71</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/20/16</td>\n",
       "      <td>3.838321</td>\n",
       "      <td>95</td>\n",
       "      <td>33.59</td>\n",
       "      <td>29.19</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>72</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/21/16</td>\n",
       "      <td>4.150010</td>\n",
       "      <td>100</td>\n",
       "      <td>33.88</td>\n",
       "      <td>45.64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>73</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/22/16</td>\n",
       "      <td>4.480766</td>\n",
       "      <td>100</td>\n",
       "      <td>31.21</td>\n",
       "      <td>26.90</td>\n",
       "      <td>0.005833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>74</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/23/16</td>\n",
       "      <td>4.828550</td>\n",
       "      <td>98</td>\n",
       "      <td>34.92</td>\n",
       "      <td>38.93</td>\n",
       "      <td>0.000521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>75</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/24/16</td>\n",
       "      <td>5.189453</td>\n",
       "      <td>96</td>\n",
       "      <td>34.52</td>\n",
       "      <td>46.39</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>76</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/25/16</td>\n",
       "      <td>5.556872</td>\n",
       "      <td>85</td>\n",
       "      <td>31.54</td>\n",
       "      <td>35.35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>77</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/26/16</td>\n",
       "      <td>5.920461</td>\n",
       "      <td>89</td>\n",
       "      <td>31.07</td>\n",
       "      <td>26.70</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>78</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/27/16</td>\n",
       "      <td>6.264949</td>\n",
       "      <td>92</td>\n",
       "      <td>31.72</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>79</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/28/16</td>\n",
       "      <td>6.569069</td>\n",
       "      <td>87</td>\n",
       "      <td>32.15</td>\n",
       "      <td>19.07</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>80</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/29/16</td>\n",
       "      <td>6.805101</td>\n",
       "      <td>78</td>\n",
       "      <td>32.18</td>\n",
       "      <td>20.15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>81</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/30/16</td>\n",
       "      <td>6.939912</td>\n",
       "      <td>83</td>\n",
       "      <td>32.58</td>\n",
       "      <td>23.51</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>82</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>7/31/16</td>\n",
       "      <td>6.938528</td>\n",
       "      <td>89</td>\n",
       "      <td>32.80</td>\n",
       "      <td>28.32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>83</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/1/16</td>\n",
       "      <td>6.770950</td>\n",
       "      <td>94</td>\n",
       "      <td>32.98</td>\n",
       "      <td>33.79</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>84</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/2/16</td>\n",
       "      <td>6.421510</td>\n",
       "      <td>95</td>\n",
       "      <td>35.21</td>\n",
       "      <td>39.23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>85</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/3/16</td>\n",
       "      <td>5.897762</td>\n",
       "      <td>90</td>\n",
       "      <td>36.43</td>\n",
       "      <td>38.14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>86</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/4/16</td>\n",
       "      <td>5.234138</td>\n",
       "      <td>95</td>\n",
       "      <td>35.89</td>\n",
       "      <td>38.49</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>87</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/5/16</td>\n",
       "      <td>4.486770</td>\n",
       "      <td>81</td>\n",
       "      <td>35.14</td>\n",
       "      <td>28.45</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>88</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/6/16</td>\n",
       "      <td>3.720411</td>\n",
       "      <td>73</td>\n",
       "      <td>35.28</td>\n",
       "      <td>24.72</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>89</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/7/16</td>\n",
       "      <td>2.993216</td>\n",
       "      <td>71</td>\n",
       "      <td>34.67</td>\n",
       "      <td>26.89</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/8/16</td>\n",
       "      <td>2.346042</td>\n",
       "      <td>72</td>\n",
       "      <td>35.06</td>\n",
       "      <td>25.65</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>91</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/9/16</td>\n",
       "      <td>1.799330</td>\n",
       "      <td>85</td>\n",
       "      <td>34.13</td>\n",
       "      <td>37.64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>92</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/10/16</td>\n",
       "      <td>1.356225</td>\n",
       "      <td>97</td>\n",
       "      <td>35.14</td>\n",
       "      <td>47.99</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>93</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/11/16</td>\n",
       "      <td>1.008475</td>\n",
       "      <td>97</td>\n",
       "      <td>32.33</td>\n",
       "      <td>67.36</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>94</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/12/16</td>\n",
       "      <td>0.742180</td>\n",
       "      <td>88</td>\n",
       "      <td>32.00</td>\n",
       "      <td>47.62</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>95</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/13/16</td>\n",
       "      <td>0.541986</td>\n",
       "      <td>83</td>\n",
       "      <td>34.74</td>\n",
       "      <td>51.59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>96</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/14/16</td>\n",
       "      <td>0.393529</td>\n",
       "      <td>87</td>\n",
       "      <td>35.60</td>\n",
       "      <td>49.24</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>97</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/15/16</td>\n",
       "      <td>0.284536</td>\n",
       "      <td>89</td>\n",
       "      <td>34.13</td>\n",
       "      <td>42.74</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>98</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/16/16</td>\n",
       "      <td>0.205101</td>\n",
       "      <td>93</td>\n",
       "      <td>36.76</td>\n",
       "      <td>68.52</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>99</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/17/16</td>\n",
       "      <td>0.147515</td>\n",
       "      <td>90</td>\n",
       "      <td>37.08</td>\n",
       "      <td>64.36</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>100</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>1 # 2 # 4 # 5 # 6</td>\n",
       "      <td>8/18/16</td>\n",
       "      <td>0.105927</td>\n",
       "      <td>93</td>\n",
       "      <td>34.09</td>\n",
       "      <td>66.44</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DAP Gen Loc            PlantID     Date  GrowthRate  Temperature  \\\n",
       "0      1   A   K  1 # 2 # 4 # 5 # 6   5/4/16    0.035015           67   \n",
       "1      2   A   K  1 # 2 # 4 # 5 # 6   5/5/16    0.038041           77   \n",
       "2      3   A   K  1 # 2 # 4 # 5 # 6   5/6/16    0.041329           83   \n",
       "3      4   A   K  1 # 2 # 4 # 5 # 6   5/7/16    0.044901           85   \n",
       "4      5   A   K  1 # 2 # 4 # 5 # 6   5/8/16    0.048783           85   \n",
       "5      6   A   K  1 # 2 # 4 # 5 # 6   5/9/16    0.052999           81   \n",
       "6      7   A   K  1 # 2 # 4 # 5 # 6  5/10/16    0.057580           76   \n",
       "7      8   A   K  1 # 2 # 4 # 5 # 6  5/11/16    0.062557           87   \n",
       "8      9   A   K  1 # 2 # 4 # 5 # 6  5/12/16    0.067964           72   \n",
       "9     10   A   K  1 # 2 # 4 # 5 # 6  5/13/16    0.073839           75   \n",
       "10    11   A   K  1 # 2 # 4 # 5 # 6  5/14/16    0.080221           81   \n",
       "11    12   A   K  1 # 2 # 4 # 5 # 6  5/15/16    0.087155           57   \n",
       "12    13   A   K  1 # 2 # 4 # 5 # 6  5/16/16    0.094688           61   \n",
       "13    14   A   K  1 # 2 # 4 # 5 # 6  5/17/16    0.102872           57   \n",
       "14    15   A   K  1 # 2 # 4 # 5 # 6  5/18/16    0.111764           58   \n",
       "15    16   A   K  1 # 2 # 4 # 5 # 6  5/19/16    0.121424           65   \n",
       "16    17   A   K  1 # 2 # 4 # 5 # 6  5/20/16    0.131920           64   \n",
       "17    18   A   K  1 # 2 # 4 # 5 # 6  5/21/16    0.143322           72   \n",
       "18    19   A   K  1 # 2 # 4 # 5 # 6  5/22/16    0.155710           85   \n",
       "19    20   A   K  1 # 2 # 4 # 5 # 6  5/23/16    0.169169           87   \n",
       "20    21   A   K  1 # 2 # 4 # 5 # 6  5/24/16    0.183791           84   \n",
       "21    22   A   K  1 # 2 # 4 # 5 # 6  5/25/16    0.199677           93   \n",
       "22    23   A   K  1 # 2 # 4 # 5 # 6  5/26/16    0.216936           93   \n",
       "23    24   A   K  1 # 2 # 4 # 5 # 6  5/27/16    0.235687           88   \n",
       "24    25   A   K  1 # 2 # 4 # 5 # 6  5/28/16    0.256059           77   \n",
       "25    26   A   K  1 # 2 # 4 # 5 # 6  5/29/16    0.278191           81   \n",
       "26    27   A   K  1 # 2 # 4 # 5 # 6  5/30/16    0.302237           86   \n",
       "27    28   A   K  1 # 2 # 4 # 5 # 6  5/31/16    0.328360           87   \n",
       "28    29   A   K  1 # 2 # 4 # 5 # 6   6/1/16    0.356742           75   \n",
       "29    30   A   K  1 # 2 # 4 # 5 # 6   6/2/16    0.387577           75   \n",
       "..   ...  ..  ..                ...      ...         ...          ...   \n",
       "370   71   B   N  1 # 2 # 4 # 5 # 6  7/20/16    3.838321           95   \n",
       "371   72   B   N  1 # 2 # 4 # 5 # 6  7/21/16    4.150010          100   \n",
       "372   73   B   N  1 # 2 # 4 # 5 # 6  7/22/16    4.480766          100   \n",
       "373   74   B   N  1 # 2 # 4 # 5 # 6  7/23/16    4.828550           98   \n",
       "374   75   B   N  1 # 2 # 4 # 5 # 6  7/24/16    5.189453           96   \n",
       "375   76   B   N  1 # 2 # 4 # 5 # 6  7/25/16    5.556872           85   \n",
       "376   77   B   N  1 # 2 # 4 # 5 # 6  7/26/16    5.920461           89   \n",
       "377   78   B   N  1 # 2 # 4 # 5 # 6  7/27/16    6.264949           92   \n",
       "378   79   B   N  1 # 2 # 4 # 5 # 6  7/28/16    6.569069           87   \n",
       "379   80   B   N  1 # 2 # 4 # 5 # 6  7/29/16    6.805101           78   \n",
       "380   81   B   N  1 # 2 # 4 # 5 # 6  7/30/16    6.939912           83   \n",
       "381   82   B   N  1 # 2 # 4 # 5 # 6  7/31/16    6.938528           89   \n",
       "382   83   B   N  1 # 2 # 4 # 5 # 6   8/1/16    6.770950           94   \n",
       "383   84   B   N  1 # 2 # 4 # 5 # 6   8/2/16    6.421510           95   \n",
       "384   85   B   N  1 # 2 # 4 # 5 # 6   8/3/16    5.897762           90   \n",
       "385   86   B   N  1 # 2 # 4 # 5 # 6   8/4/16    5.234138           95   \n",
       "386   87   B   N  1 # 2 # 4 # 5 # 6   8/5/16    4.486770           81   \n",
       "387   88   B   N  1 # 2 # 4 # 5 # 6   8/6/16    3.720411           73   \n",
       "388   89   B   N  1 # 2 # 4 # 5 # 6   8/7/16    2.993216           71   \n",
       "389   90   B   N  1 # 2 # 4 # 5 # 6   8/8/16    2.346042           72   \n",
       "390   91   B   N  1 # 2 # 4 # 5 # 6   8/9/16    1.799330           85   \n",
       "391   92   B   N  1 # 2 # 4 # 5 # 6  8/10/16    1.356225           97   \n",
       "392   93   B   N  1 # 2 # 4 # 5 # 6  8/11/16    1.008475           97   \n",
       "393   94   B   N  1 # 2 # 4 # 5 # 6  8/12/16    0.742180           88   \n",
       "394   95   B   N  1 # 2 # 4 # 5 # 6  8/13/16    0.541986           83   \n",
       "395   96   B   N  1 # 2 # 4 # 5 # 6  8/14/16    0.393529           87   \n",
       "396   97   B   N  1 # 2 # 4 # 5 # 6  8/15/16    0.284536           89   \n",
       "397   98   B   N  1 # 2 # 4 # 5 # 6  8/16/16    0.205101           93   \n",
       "398   99   B   N  1 # 2 # 4 # 5 # 6  8/17/16    0.147515           90   \n",
       "399  100   B   N  1 # 2 # 4 # 5 # 6  8/18/16    0.105927           93   \n",
       "\n",
       "     Solar.Rad  Humidity  Rainfall  \n",
       "0        22.28     52.82  0.000000  \n",
       "1        22.32     60.94  0.000000  \n",
       "2        26.10     81.27  0.000000  \n",
       "3        23.08     65.71  0.000000  \n",
       "4        22.64     62.41  0.000000  \n",
       "5        20.30     47.66  0.000000  \n",
       "6        21.31     47.93  0.000000  \n",
       "7        22.32     49.38  0.000000  \n",
       "8        23.33     67.23  0.000000  \n",
       "9        25.09     83.94  0.000000  \n",
       "10       20.38     64.41  0.000000  \n",
       "11       19.15     52.71  0.000000  \n",
       "12       21.85     52.64  0.000000  \n",
       "13       22.79     66.06  0.000000  \n",
       "14       22.18     65.08  0.000000  \n",
       "15       21.64     56.00  0.000000  \n",
       "16       24.88     83.16  0.000000  \n",
       "17       23.80     64.87  0.000000  \n",
       "18       23.40     71.21  0.000000  \n",
       "19       19.22     52.67  0.000000  \n",
       "20       22.64     56.57  0.000000  \n",
       "21       24.52     74.88  0.000000  \n",
       "22       24.08     76.57  0.000000  \n",
       "23       24.08     69.32  0.000000  \n",
       "24       23.72     67.65  0.000000  \n",
       "25       22.64     62.15  0.000000  \n",
       "26       25.45     72.08  0.000000  \n",
       "27       26.68     78.11  0.000000  \n",
       "28       26.24     82.57  0.000000  \n",
       "29       21.85     61.87  0.000000  \n",
       "..         ...       ...       ...  \n",
       "370      33.59     29.19  0.000000  \n",
       "371      33.88     45.64  0.000000  \n",
       "372      31.21     26.90  0.005833  \n",
       "373      34.92     38.93  0.000521  \n",
       "374      34.52     46.39  0.000000  \n",
       "375      31.54     35.35  0.000000  \n",
       "376      31.07     26.70  0.000000  \n",
       "377      31.72     22.00  0.000000  \n",
       "378      32.15     19.07  0.007812  \n",
       "379      32.18     20.15  0.000000  \n",
       "380      32.58     23.51  0.000000  \n",
       "381      32.80     28.32  0.000000  \n",
       "382      32.98     33.79  0.000000  \n",
       "383      35.21     39.23  0.000000  \n",
       "384      36.43     38.14  0.000000  \n",
       "385      35.89     38.49  0.000000  \n",
       "386      35.14     28.45  0.000000  \n",
       "387      35.28     24.72  0.000000  \n",
       "388      34.67     26.89  0.000000  \n",
       "389      35.06     25.65  0.000104  \n",
       "390      34.13     37.64  0.000000  \n",
       "391      35.14     47.99  0.000000  \n",
       "392      32.33     67.36  0.000104  \n",
       "393      32.00     47.62  0.000104  \n",
       "394      34.74     51.59  0.000000  \n",
       "395      35.60     49.24  0.000000  \n",
       "396      34.13     42.74  0.000000  \n",
       "397      36.76     68.52  0.000000  \n",
       "398      37.08     64.36  0.000000  \n",
       "399      34.09     66.44  0.000313  \n",
       "\n",
       "[400 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf.loc[95:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf = df_sf.drop(['PlantID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf = df_sf.drop(['Date', 'Loc', 'Gen', 'PlantID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf.loc[90:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame()\n",
    "y_train = np.array([])\n",
    "X_test = pd.DataFrame()\n",
    "y_test = np.array([])\n",
    "true_index_counter = -1\n",
    "for i in range (0, int(len(df_sf)/100)):\n",
    "    for k in range (1, 101):\n",
    "        true_index_counter += 1\n",
    "        if k <= 95:\n",
    "#             X_train = pd.concat([X_train, df_sf.loc[true_index_counter].drop(['GrowthRate'])])\n",
    "            X_train = X_train.append(df_sf.loc[true_index_counter].drop(['GrowthRate']))\n",
    "            print(true_index_counter)\n",
    "            \n",
    "#             y_train = pd.concat([y_train, df_sf.loc[true_index_counter, 'GrowthRate']])\n",
    "            y_train = np.append(y_train, df_sf.loc[true_index_counter, 'GrowthRate'])\n",
    "        else:\n",
    "            X_test = X_test.append(df_sf.loc[true_index_counter].drop(['GrowthRate']))\n",
    "#             y_train = pd.concat([y_train, df_sf.loc[true_index_counter, 'GrowthRate']])\n",
    "            y_test = np.append(y_test, df_sf.loc[true_index_counter, 'GrowthRate'])\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(n_estimators=20, max_depth=13, random_state=0, verbose=1, n_jobs=-1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "preds = pd.DataFrame(preds)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "evaluate_errors(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up-to-date with 'origin/master'.\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   Syngenta_yield_prediction_used_modules.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(n_estimators=1000, learning_rate=0.01)\n",
    "clf.fit(X_train, np.log1p(y_train))\n",
    "preds = np.expm1(clf.predict(X_test))\n",
    "\n",
    "preds = pd.DataFrame(preds)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "evaluate_errors(preds, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
