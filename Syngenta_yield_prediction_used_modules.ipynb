{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# READ THE CSV INTO DATAFRAME\n",
    "\n",
    "df = pd.read_csv('Syngenta/Syngenta_2017/Experiment_dataset.csv')\n",
    "\n",
    "np_ar = np.asarray(df)\n",
    "# df2 = pd.read_csv('Syngenta/Syngenta_2017/Region_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.Temperature.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY NECESSARY IF: USING 174 ADDITIONAL VARIETY COLUMNS METHOD\n",
    "\n",
    "# THIS IS A DIFFERENT APPROACH TO THE ABOVE FOUR CELLS, WHERE WE HAVE 174 ADDITIONAL FEATURE COLUMNS\n",
    "# EACH WITH A 0 (IF IT IS NOT OF THAT VARIETY) OR A 1 (IF IT IS OF THAT VARIETY)\n",
    "\n",
    "# print(df)\n",
    "variety_dummies = pd.get_dummies(df.Variety)\n",
    "# print(dummies)\n",
    "df = pd.concat([df, variety_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GOAL OF THIS MODULE:\n",
    "# Encode the planting date as a season\n",
    "\n",
    "# remove the dates that are \".\"\n",
    "df = df[~df['Planting date'].str.match(\"\\.\")]\n",
    "plant_date = df['Planting date'].apply(lambda dt: pd.to_datetime(dt))\n",
    "plant_date = plant_date.rename(\"Season\")\n",
    "plant_date = pd.to_datetime(plant_date)\n",
    "plant_date = plant_date.apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# df['Plant date'] = pd.to_datetime(df['Plant date'])\n",
    "df = pd.concat([df, plant_date], axis=1)\n",
    "\n",
    "# plant_date = pd.to_datetime(df['Planting date'], infer_datetime_format=True)\n",
    "# df = df['Planting date'].apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# pd.get_dummies(df['Planting date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Plant date'] = df['Plant date'].apply(lambda dt: (dt.month%12 + 3)//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        2\n",
       "4        2\n",
       "5        2\n",
       "6        2\n",
       "7        2\n",
       "8        2\n",
       "9        2\n",
       "10       2\n",
       "11       2\n",
       "12       2\n",
       "13       2\n",
       "14       2\n",
       "15       2\n",
       "16       2\n",
       "17       2\n",
       "18       2\n",
       "19       2\n",
       "20       2\n",
       "21       2\n",
       "22       2\n",
       "23       2\n",
       "24       2\n",
       "25       2\n",
       "26       2\n",
       "27       2\n",
       "28       2\n",
       "29       2\n",
       "        ..\n",
       "82006    3\n",
       "82007    3\n",
       "82008    3\n",
       "82009    3\n",
       "82010    3\n",
       "82011    3\n",
       "82012    3\n",
       "82013    3\n",
       "82014    3\n",
       "82015    3\n",
       "82016    3\n",
       "82017    3\n",
       "82018    3\n",
       "82019    3\n",
       "82020    3\n",
       "82021    3\n",
       "82022    3\n",
       "82023    3\n",
       "82024    3\n",
       "82025    3\n",
       "82026    3\n",
       "82027    3\n",
       "82028    3\n",
       "82029    3\n",
       "82030    3\n",
       "82031    3\n",
       "82032    3\n",
       "82033    3\n",
       "82034    3\n",
       "82035    3\n",
       "Name: Plant date, Length: 80086, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Plant date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Experiment', 'Location', 'Variety', 'Planting date', 'Yield',\n",
      "       'Check Yield', 'Yield difference', 'Year', 'Latitude', 'Longitude',\n",
      "       'Temperature', 'Precipitation', 'Solar Radiation', 'Soil class', 'CEC',\n",
      "       'Organic matter', 'pH', 'Clay', 'Silt', 'Sand', 'PI', 'Area',\n",
      "       'Plant date'],\n",
      "      dtype='object')\n",
      "Experiment          0\n",
      "Location            0\n",
      "Variety             0\n",
      "Planting date       0\n",
      "Yield               0\n",
      "Check Yield         0\n",
      "Yield difference    0\n",
      "Year                0\n",
      "Latitude            0\n",
      "Longitude           0\n",
      "Temperature         0\n",
      "Precipitation       0\n",
      "Solar Radiation     0\n",
      "Soil class          0\n",
      "CEC                 0\n",
      "Organic matter      0\n",
      "pH                  0\n",
      "Clay                0\n",
      "Silt                0\n",
      "Sand                0\n",
      "PI                  0\n",
      "Area                0\n",
      "Plant date          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LATITUDE AND LONGITUDE CLUSTERING INTO FEATURES\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "latlong = df.loc[:, ['Latitude', 'Longitude']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(latlong)\n",
    "kmeans.labels_.shape\n",
    "lat_long_dummies = pd.get_dummies(kmeans.labels_).rename(index=int, columns={0: \"Loc Clust 0\", 1: \"Loc Clust 1\", 2: \"Loc Clust 2\", 3: \"Loc Clust 3\"})\n",
    "df = pd.concat([df, lat_long_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment          1950\n",
      "Location            1950\n",
      "Variety             1950\n",
      "Planting date       1950\n",
      "Yield               1950\n",
      "Check Yield         1950\n",
      "Yield difference    1950\n",
      "Year                1950\n",
      "Latitude            1950\n",
      "Longitude           1950\n",
      "Temperature         1950\n",
      "Precipitation       1950\n",
      "Solar Radiation     1950\n",
      "Soil class          1950\n",
      "CEC                 1950\n",
      "Organic matter      1950\n",
      "pH                  1950\n",
      "Clay                1950\n",
      "Silt                1950\n",
      "Sand                1950\n",
      "PI                  1950\n",
      "Area                1950\n",
      "Plant date          1950\n",
      "Loc Clust 0         1950\n",
      "Loc Clust 1         1950\n",
      "Loc Clust 2         1950\n",
      "Loc Clust 3         1950\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Experiment', 'Location', 'Variety', 'Planting date', 'Yield',\n",
      "       'Check Yield', 'Yield difference', 'Year', 'Latitude', 'Longitude',\n",
      "       'Temperature', 'Precipitation', 'Solar Radiation', 'Soil class', 'CEC',\n",
      "       'Organic matter', 'pH', 'Clay', 'Silt', 'Sand', 'PI', 'Area',\n",
      "       'Plant date', 'Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2',\n",
      "       'Loc Clust 3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df = df[~df.Silt.isnull()]\n",
    "df = df[~df['Loc Clust 1'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "binarized = lb.fit(df.Variety)\n",
    "print(binarized)\n",
    "df.Variety = pd.Series(binarized.transform(df.Variety))\n",
    "print(binarized.transform(df.Variety).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Yield', 'Year', 'Temperature', 'Precipitation', 'Solar Radiation',\n",
      "       'Soil class', 'CEC', 'Organic matter', 'pH', 'Clay', 'Silt', 'Sand',\n",
      "       'Area', 'Plant date', 'Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2',\n",
      "       'Loc Clust 3', 'YieldBucket'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# DROP ALL THE CELLS THAT ARE NOT USABLE SUCH AS THE ONES THAT ARE STRINGS OR DATES\n",
    "\n",
    "# set if want to drop some columns specifically\n",
    "should_drop = 1\n",
    "columns_to_drop = ['Experiment', 'Location',\n",
    "                   'Check Yield', 'Yield difference', 'Latitude',\n",
    "                   'Longitude', 'Variety', 'PI', 'Planting date']\n",
    "\n",
    "# set if want to keep some columns specifically\n",
    "should_keep = 0\n",
    "# columns_to_keep = ['Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2', 'Loc Clust 3']\n",
    "columns_to_keep = ['Silt', 'Precipitation', 'Temperature']\n",
    "MUST_HAVE_COLUMNS = ['Yield']\n",
    "# print(columns_to_keep)\n",
    "\n",
    "df = df.drop(columns_to_drop, axis=1) if should_drop else df\n",
    "df = df.loc[:, columns_to_keep + MUST_HAVE_COLUMNS] if should_keep else df\n",
    "df['YieldBucket'] = pd.Series(pd.qcut(df.Yield, q=3, labels=[\"high\", \"medium\", \"low\"]))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We expect to be 0 nan values and there actually are 0 nan values\n",
      "\n",
      "Yield              0\n",
      "Year               0\n",
      "Temperature        0\n",
      "Precipitation      0\n",
      "Solar Radiation    0\n",
      "Soil class         0\n",
      "CEC                0\n",
      "Organic matter     0\n",
      "pH                 0\n",
      "Clay               0\n",
      "Silt               0\n",
      "Sand               0\n",
      "Area               0\n",
      "Plant date         0\n",
      "Loc Clust 0        0\n",
      "Loc Clust 1        0\n",
      "Loc Clust 2        0\n",
      "Loc Clust 3        0\n",
      "YieldBucket        0\n",
      "dtype: int64\n",
      "Yield <class 'numpy.float64'>\n",
      "Year <class 'numpy.float64'>\n",
      "Temperature <class 'numpy.float64'>\n",
      "Precipitation <class 'numpy.float64'>\n",
      "Solar Radiation <class 'numpy.float64'>\n",
      "Soil class <class 'numpy.float64'>\n",
      "CEC <class 'numpy.float64'>\n",
      "Organic matter <class 'numpy.float64'>\n",
      "pH <class 'numpy.float64'>\n",
      "Clay <class 'numpy.float64'>\n",
      "Silt <class 'numpy.float64'>\n",
      "Sand <class 'numpy.float64'>\n",
      "Area <class 'numpy.float64'>\n",
      "Plant date <class 'numpy.float64'>\n",
      "Loc Clust 0 <class 'numpy.float64'>\n",
      "Loc Clust 1 <class 'numpy.float64'>\n",
      "Loc Clust 2 <class 'numpy.float64'>\n",
      "Loc Clust 3 <class 'numpy.float64'>\n",
      "YieldBucket <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# LET US ALSO MAKE SURE THERE ARE NO NAN IN THE DATA\n",
    "print(\"We expect to be %s nan values and there actually are %s nan values\\n\" % (0, np.sum(df.isnull().sum())))\n",
    "print(df.isnull().sum())\n",
    "# AFTER COLUMNS, MAKE SURE NO SKETCHY ONES\n",
    "for col in df.columns:\n",
    "    print(col, type(df[col][0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Temperature', 'Precipitation', 'Solar Radiation', 'Soil class',\n",
      "       'CEC', 'Organic matter', 'pH', 'Clay', 'Silt', 'Sand', 'Area',\n",
      "       'Plant date', 'Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2',\n",
      "       'Loc Clust 3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT\n",
    "\n",
    "X = df.drop(['Yield', 'YieldBucket'], axis=1)\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "y = df.Yield\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, train_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7813, 17) \n",
      "y_train shape: (7813,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape, \"\\ny_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will evaluate the errors based on RMSE (from the challenge spec)\n",
    "# also will evaluate based on average error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def evaluate_errors(prediction, actual):\n",
    "    print(\"RMSE Error: \", np.sqrt(mean_squared_error(prediction, actual)))\n",
    "    avg_error_vector = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "#     print(\"Average Error: \", np.mean(avg_error_vector))\n",
    "    print(\"Average Error details:\\n\", avg_error_vector.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Error:  7.569704667297518\n",
      "Average Error details:\n",
      " count    3907.000000\n",
      "mean       10.705794\n",
      "std        11.583171\n",
      "min         0.007068\n",
      "25%         3.436881\n",
      "50%         7.834823\n",
      "75%        13.862608\n",
      "max       219.736525\n",
      "Name: Yield, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=0, verbose=1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "evaluate_errors(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    62372\n",
       "3.0    15742\n",
       "4.0       22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['Plant date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soil class has importance:  0.01733528048975531\n",
      "Loc Clust 0 has importance:  0.017618173355426158\n",
      "Loc Clust 3 has importance:  0.018926084966503366\n",
      "Loc Clust 1 has importance:  0.01957171783899267\n",
      "Loc Clust 2 has importance:  0.019668117194292456\n",
      "Plant date has importance:  0.03201553224375252\n",
      "Clay has importance:  0.034371709380952915\n",
      "Sand has importance:  0.04476461719153968\n",
      "CEC has importance:  0.057496437342252384\n",
      "pH has importance:  0.05931139328608352\n",
      "Area has importance:  0.06479587829164976\n",
      "Solar Radiation has importance:  0.08298906786646205\n",
      "Year has importance:  0.08359305647515082\n",
      "Temperature has importance:  0.08913024637760716\n",
      "Organic matter has importance:  0.09146143108245394\n",
      "Precipitation has importance:  0.10483892087297993\n",
      "Silt has importance:  0.1621123357441453\n"
     ]
    }
   ],
   "source": [
    "# GET OUTPUT OF FEATURE IMPORTANCE\n",
    "\n",
    "feature_importances = regr.feature_importances_\n",
    "feature_importances = pd.Series(feature_importances)\n",
    "feature_importance_df = pd.DataFrame({'feature': X_train.columns,'feature_importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by=['feature_importance'])\n",
    "for index, row in feature_importance_df.iterrows():\n",
    "    print(row['feature'], 'has importance: ', row['feature_importance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WILL ONLY WORK WITH THE BUCKET METHOD\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "regr = RandomForestClassifier(n_estimators=10, max_depth=20, random_state=0, verbose=1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "classifiers = [\n",
    "    svm.SVR(),\n",
    "    MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=1),\n",
    "    linear_model.SGDRegressor(),\n",
    "    linear_model.BayesianRidge(),\n",
    "    linear_model.LassoLars(),\n",
    "#     linear_model.ARDRegression(),\n",
    "#     linear_model.ARDRegression(),\n",
    "    linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.TheilSenRegressor(),\n",
    "    linear_model.LinearRegression()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# estimator = svm.SVR(kernel=\"linear\")\n",
    "\n",
    "# selector = RFECV(estimator, step=1, cv=5, verbose=1)\n",
    "# selector = selector.fit(X_train, y_train)\n",
    "# selector.support_ \n",
    "# # array([ True,  True,  True,  True,  True,\n",
    "# #         False, False, False, False, False], dtype=bool)\n",
    "# selector.ranking_\n",
    "# # array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])\n",
    "\n",
    "\n",
    "#     print(np.sum(preds - y_test))\n",
    "#     print(clf.predict(X_test),'\\n')\n",
    "#     print(y_test)\n",
    "#     print('accuracy score:', accuracy_score(y_test, clf.predict(X_test)), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    errors = mean_squared_error(preds, y_test)\n",
    "#     errors = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "#     print(errors)\n",
    "    print(errors)\n",
    "#     print(errors.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#     DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "from sklearn.metrics import accuracy_score\n",
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(scale(X_train), y_train)\n",
    "    preds = clf.predict(scale(X_test))\n",
    "    print(accuracy_score(y_test, preds))\n",
    "#     errors = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "#     print(errors)\n",
    "#     print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
