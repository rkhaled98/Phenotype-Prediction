{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# READ THE CSV INTO DATAFRAME\n",
    "\n",
    "df = pd.read_csv('Syngenta/Syngenta_2017/Experiment_dataset.csv')\n",
    "\n",
    "# np_ar = np.asarray(df)\n",
    "# df2 = pd.read_csv('Syngenta/Syngenta_2017/Region_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Planting date'][[np.random.randn]])\n",
    "# print(df.columns)\n",
    "# print(df.Temperature.describe())\n",
    "# import random\n",
    "# for i in range(0, 500):\n",
    "#     print(random.choice(df['Planting date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Yield.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]),)\n",
      "['V000016' 'V000017' 'V000018' 'V000023' 'V000024' 'V000025' 'V000030'\n",
      " 'V000032' 'V000034' 'V000036' 'V000039' 'V000047' 'V000050' 'V000051'\n",
      " 'V000058' 'V000060' 'V000062' 'V000067' 'V000070' 'V000071' 'V000075'\n",
      " 'V000078' 'V000079' 'V000080' 'V000081' 'V000082' 'V000092' 'V000096'\n",
      " 'V000098' 'V000110' 'V000115' 'V000122' 'V000123' 'V000124' 'V000125'\n",
      " 'V000134' 'V000147' 'V000157' 'V000172' 'V000721' 'V031243' 'V051214'\n",
      " 'V103132' 'V103136' 'V103139' 'V103142' 'V103150' 'V103155' 'V103156'\n",
      " 'V103159' 'V103163' 'V103173' 'V103193' 'V103198' 'V103259' 'V103266'\n",
      " 'V103273' 'V103277' 'V103281' 'V103286' 'V103293' 'V103302' 'V103303'\n",
      " 'V103308' 'V103332' 'V103425' 'V103466' 'V103620' 'V103624' 'V103866'\n",
      " 'V103970' 'V104000' 'V110768' 'V110890' 'V110923' 'V111237' 'V111336'\n",
      " 'V113396' 'V113424' 'V113476' 'V114530' 'V114541' 'V114545' 'V114553'\n",
      " 'V114564' 'V114565' 'V114655' 'V114944' 'V114951' 'V119975' 'V120038'\n",
      " 'V120047' 'V120246' 'V120410' 'V120585' 'V120810' 'V120912' 'V120999'\n",
      " 'V121015' 'V121097' 'V121140' 'V121524' 'V124343' 'V130305' 'V130307'\n",
      " 'V130308' 'V131675' 'V131778' 'V136868' 'V137136' 'V137147' 'V137160'\n",
      " 'V137237' 'V137289' 'V139094' 'V139107' 'V139548' 'V140091' 'V140364'\n",
      " 'V140784' 'V150834' 'V150844' 'V150847' 'V150853' 'V150974' 'V151036'\n",
      " 'V151236' 'V151273' 'V151284' 'V151329' 'V151331' 'V151332' 'V151333'\n",
      " 'V151334' 'V151336' 'V151337' 'V151340' 'V151399' 'V151407' 'V152053'\n",
      " 'V152061' 'V152067' 'V152079' 'V152102' 'V152253' 'V152300' 'V152312'\n",
      " 'V152320' 'V152322' 'V152440' 'V152734' 'V152779' 'V155180' 'V155820'\n",
      " 'V155842' 'V155843' 'V155918' 'V156247' 'V156305' 'V156314' 'V156367'\n",
      " 'V156368' 'V156516' 'V156553' 'V156565' 'V156574' 'V156642' 'V156763'\n",
      " 'V156774' 'V156783' 'V156786' 'V156797' 'V156806' 'V156807']\n",
      "0         11\n",
      "1         11\n",
      "2         11\n",
      "3         11\n",
      "4        104\n",
      "5          5\n",
      "6          4\n",
      "7        104\n",
      "8         33\n",
      "9          5\n",
      "10         4\n",
      "11       104\n",
      "12        33\n",
      "13         5\n",
      "14       114\n",
      "15         4\n",
      "16         3\n",
      "17        33\n",
      "18       114\n",
      "19         4\n",
      "20         3\n",
      "21        33\n",
      "22        34\n",
      "23        13\n",
      "24         5\n",
      "25        13\n",
      "26         5\n",
      "27        13\n",
      "28         5\n",
      "29        13\n",
      "        ... \n",
      "82006    109\n",
      "82007     77\n",
      "82008    149\n",
      "82009     91\n",
      "82010    151\n",
      "82011     98\n",
      "82012    109\n",
      "82013     77\n",
      "82014    149\n",
      "82015     91\n",
      "82016     98\n",
      "82017    109\n",
      "82018     77\n",
      "82019    149\n",
      "82020    108\n",
      "82021     98\n",
      "82022    109\n",
      "82023     77\n",
      "82024    149\n",
      "82025    108\n",
      "82026     98\n",
      "82027    109\n",
      "82028     77\n",
      "82029    149\n",
      "82030    108\n",
      "82031     98\n",
      "82032    109\n",
      "82033     77\n",
      "82034    149\n",
      "82035    108\n",
      "Name: Variety, Length: 82036, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "UNIQUE_VARIETIES = np.unique(df.Variety)\n",
    "INDICES = [i for i in range(0, len(UNIQUE_VARIETIES))]\n",
    "print(np.where(UNIQUE_VARIETIES=='V000017'))\n",
    "df.Variety = df.Variety.apply(lambda var: np.where(UNIQUE_VARIETIES==var)[0][0])\n",
    "print(UNIQUE_VARIETIES)\n",
    "print(df.Variety)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=True)\n",
      "  (0, 150)\t1\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer(sparse_output=True)\n",
    "binarized = lb.fit(df.Variety)\n",
    "print(binarized)\n",
    "binarized.transform(df.Variety)\n",
    "# df.Variety = pd.Series(binarized.transform(df.Variety))\n",
    "# print(len(binarized.transform(df.Variety).reshape(1,-1)[0]))\n",
    "print(binarized.transform([150]))\n",
    "print(binarized.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    82036.000000\n",
       "mean        99.718392\n",
       "std         51.649029\n",
       "min          0.000000\n",
       "25%         50.000000\n",
       "50%        104.000000\n",
       "75%        154.000000\n",
       "max        173.000000\n",
       "Name: Variety, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Variety.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY NECESSARY IF: USING 174 ADDITIONAL VARIETY COLUMNS METHOD\n",
    "\n",
    "# THIS IS A DIFFERENT APPROACH TO THE ABOVE FOUR CELLS, WHERE WE HAVE 174 ADDITIONAL FEATURE COLUMNS\n",
    "# EACH WITH A 0 (IF IT IS NOT OF THAT VARIETY) OR A 1 (IF IT IS OF THAT VARIETY)\n",
    "\n",
    "# print(df)\n",
    "variety_dummies = pd.get_dummies(df.Variety)\n",
    "# print(dummies)\n",
    "df = pd.concat([df, variety_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL VARIETY DISTRIBUTION ANALYSIS\n",
    "\n",
    "print(variety_dummies.sum().describe())\n",
    "print(np.sort(variety_dummies.sum()))\n",
    "for idx, cl in enumerate(variety_dummies.sum()):\n",
    "    print(variety_dummies.columns[idx], cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL OF THIS MODULE:\n",
    "# Encode the planting date as a season\n",
    "# NEW GOAL:\n",
    "# GET DUMMIES FOR SEASONS\n",
    "\n",
    "# remove the dates that are \".\"\n",
    "df = df[~df['Planting date'].str.match(\"\\.\")]\n",
    "plant_date = df['Planting date'].apply(lambda dt: pd.to_datetime(dt))\n",
    "plant_months = plant_date.apply(lambda dt: dt.month)\n",
    "season = plant_date.rename(\"Season\")\n",
    "season = pd.to_datetime(season)\n",
    "season = season.apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# df['Plant date'] = pd.to_datetime(df['Plant date'])\n",
    "df = pd.concat([df, season], axis=1)\n",
    "\n",
    "# plant_date = pd.to_datetime(df['Planting date'], infer_datetime_format=True)\n",
    "# df = df['Planting date'].apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# pd.get_dummies(df['Planting date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD MONTH OF MAY AND JUNE ONE HOT ENCODING INTO THE DATAFRAME\n",
    "pd.get_dummies(plant_months).sum()\n",
    "june = pd.get_dummies(plant_months).loc[:,6]\n",
    "june = june.rename(\"June\")\n",
    "may = pd.get_dummies(plant_months).loc[:,5]\n",
    "may = may.rename(\"May\")\n",
    "df = pd.concat([df, may], axis=1)\n",
    "df = pd.concat([df, june], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Season']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LATITUDE AND LONGITUDE CLUSTERING INTO FEATURES\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "latlong = df.loc[:, ['Latitude', 'Longitude']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(latlong)\n",
    "kmeans.labels_.shape\n",
    "lat_long_dummies = pd.get_dummies(kmeans.labels_)\n",
    "lat_long_dummies = lat_long_dummies.rename(index=int, columns={0: \"Loc Clust 0\",\n",
    "                                                               1: \"Loc Clust 1\",\n",
    "                                                               2: \"Loc Clust 2\",\n",
    "                                                               3: \"Loc Clust 3\"})\n",
    "df = pd.concat([df, lat_long_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(df.iloc[:, df.columns.str.match('V\\d\\d\\d\\d\\d\\d')].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS A VISUALIZATION FOR LATITUDE AND LONGITUDE CLUSTERING\n",
    "\n",
    "cent = kmeans.cluster_centers_\n",
    "clust_labels = kmeans.labels_\n",
    "means = pd.DataFrame(clust_labels)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(df['Latitude'],df['Longitude'],\n",
    "                     c=means[0], s=50)\n",
    "ax.set_title('K-Means Clustering')\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')\n",
    "plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP ALL THE CELLS THAT ARE NOT USABLE SUCH AS THE ONES THAT ARE STRINGS OR DATES\n",
    "\n",
    "# set if want to drop some columns specifically\n",
    "should_drop = 1\n",
    "columns_to_drop = ['Experiment', 'Location',\n",
    "                   'Check Yield', 'Yield difference', 'Latitude',\n",
    "                   'Longitude', 'Variety', 'PI', 'Planting date']\n",
    "\n",
    "# set if want to keep some columns specifically\n",
    "should_keep = 0\n",
    "# columns_to_keep = ['Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2', 'Loc Clust 3']\n",
    "columns_to_keep_top = ['Silt', 'Precipitation', 'Temperature', 'Solar Radiation', 'Organic matter']\n",
    "columns_VARIETIES_ONLY = np.asarray(df.iloc[:, df.columns.str.match('V\\d\\d\\d\\d\\d\\d')].columns)\n",
    "\n",
    "#set the below variable to whatever columns you want to keep\n",
    "columns_to_keep = columns_to_keep_top\n",
    "\n",
    "MUST_HAVE_COLUMNS = ['Yield']\n",
    "# print(columns_to_keep)\n",
    "\n",
    "df = df.drop(columns_to_drop, axis=1) if should_drop else df\n",
    "df = df.loc[:, np.concatenate((columns_to_keep, MUST_HAVE_COLUMNS))] if should_keep else df\n",
    "df['YieldBucket'] = pd.Series(pd.qcut(df.Yield, q=3, labels=[\"high\", \"medium\", \"low\"]))\n",
    "print(\"The final dataframe has columns: \", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.get_dummies(df.YieldBucket).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.get_dummies(df.YieldBucket).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
