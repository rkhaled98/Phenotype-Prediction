{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# READ THE CSV INTO DATAFRAME\n",
    "\n",
    "df = pd.read_csv('Syngenta/Syngenta_2017/Experiment_dataset.csv')\n",
    "\n",
    "# np_ar = np.asarray(df)\n",
    "# df2 = pd.read_csv('Syngenta/Syngenta_2017/Region_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Planting date'][[np.random.randn]])\n",
    "# print(df.columns)\n",
    "# print(df.Temperature.describe())\n",
    "# import random\n",
    "# for i in range(0, 500):\n",
    "#     print(random.choice(df['Planting date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Yield.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY NECESSARY IF: USING 174 ADDITIONAL VARIETY COLUMNS METHOD\n",
    "\n",
    "# THIS IS A DIFFERENT APPROACH TO THE ABOVE FOUR CELLS, WHERE WE HAVE 174 ADDITIONAL FEATURE COLUMNS\n",
    "# EACH WITH A 0 (IF IT IS NOT OF THAT VARIETY) OR A 1 (IF IT IS OF THAT VARIETY)\n",
    "\n",
    "# print(df)\n",
    "variety_dummies = pd.get_dummies(df.Variety)\n",
    "# print(dummies)\n",
    "df = pd.concat([df, variety_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL VARIETY DISTRIBUTION ANALYSIS\n",
    "\n",
    "print(variety_dummies.sum().describe())\n",
    "print(np.sort(variety_dummies.sum()))\n",
    "for idx, cl in enumerate(variety_dummies.sum()):\n",
    "    print(variety_dummies.columns[idx], cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Experiment', 'Location', 'Variety', 'Planting date', 'Yield',\n",
      "       'Check Yield', 'Yield difference', 'Year', 'Latitude', 'Longitude',\n",
      "       'Temperature', 'Precipitation', 'Solar Radiation', 'Soil class', 'CEC',\n",
      "       'Organic matter', 'pH', 'Clay', 'Silt', 'Sand', 'PI', 'Area'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL OF THIS MODULE:\n",
    "# Encode the planting date as a season\n",
    "# NEW GOAL:\n",
    "# GET DUMMIES FOR SEASONS\n",
    "\n",
    "# remove the dates that are \".\"\n",
    "df = df[~df['Planting date'].str.match(\"\\.\")]\n",
    "plant_date = df['Planting date'].apply(lambda dt: pd.to_datetime(dt))\n",
    "plant_months = plant_date.apply(lambda dt: dt.month)\n",
    "season = plant_date.rename(\"Season\")\n",
    "season = pd.to_datetime(season)\n",
    "season = season.apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# df['Plant date'] = pd.to_datetime(df['Plant date'])\n",
    "df = pd.concat([df, season], axis=1)\n",
    "\n",
    "# plant_date = pd.to_datetime(df['Planting date'], infer_datetime_format=True)\n",
    "# df = df['Planting date'].apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# pd.get_dummies(df['Planting date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD MONTH OF MAY AND JUNE ONE HOT ENCODING INTO THE DATAFRAME\n",
    "pd.get_dummies(plant_months).sum()\n",
    "june = pd.get_dummies(plant_months).loc[:,6]\n",
    "june = june.rename(\"June\")\n",
    "may = pd.get_dummies(plant_months).loc[:,5]\n",
    "may = may.rename(\"May\")\n",
    "df = pd.concat([df, may], axis=1)\n",
    "df = pd.concat([df, june], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Season']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LATITUDE AND LONGITUDE CLUSTERING INTO FEATURES\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "latlong = df.loc[:, ['Latitude', 'Longitude']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(latlong)\n",
    "kmeans.labels_.shape\n",
    "lat_long_dummies = pd.get_dummies(kmeans.labels_)\n",
    "lat_long_dummies = lat_long_dummies.rename(index=int, columns={0: \"Loc Clust 0\",\n",
    "                                                               1: \"Loc Clust 1\",\n",
    "                                                               2: \"Loc Clust 2\",\n",
    "                                                               3: \"Loc Clust 3\"})\n",
    "df = pd.concat([df, lat_long_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(df.iloc[:, df.columns.str.match('V\\d\\d\\d\\d\\d\\d')].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS A VISUALIZATION FOR LATITUDE AND LONGITUDE CLUSTERING\n",
    "\n",
    "cent = kmeans.cluster_centers_\n",
    "clust_labels = kmeans.labels_\n",
    "means = pd.DataFrame(clust_labels)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(df['Latitude'],df['Longitude'],\n",
    "                     c=means[0], s=50)\n",
    "ax.set_title('K-Means Clustering')\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')\n",
    "plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP ALL THE CELLS THAT ARE NOT USABLE SUCH AS THE ONES THAT ARE STRINGS OR DATES\n",
    "\n",
    "# set if want to drop some columns specifically\n",
    "should_drop = 1\n",
    "columns_to_drop = ['Experiment', 'Location',\n",
    "                   'Check Yield', 'Yield difference', 'Latitude',\n",
    "                   'Longitude', 'Variety', 'PI', 'Planting date']\n",
    "\n",
    "# set if want to keep some columns specifically\n",
    "should_keep = 0\n",
    "# columns_to_keep = ['Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2', 'Loc Clust 3']\n",
    "columns_to_keep_top = ['Silt', 'Precipitation', 'Temperature', 'Solar Radiation', 'Organic matter']\n",
    "columns_VARIETIES_ONLY = np.asarray(df.iloc[:, df.columns.str.match('V\\d\\d\\d\\d\\d\\d')].columns)\n",
    "\n",
    "#set the below variable to whatever columns you want to keep\n",
    "columns_to_keep = columns_to_keep_top\n",
    "\n",
    "MUST_HAVE_COLUMNS = ['Yield']\n",
    "# print(columns_to_keep)\n",
    "\n",
    "df = df.drop(columns_to_drop, axis=1) if should_drop else df\n",
    "df = df.loc[:, np.concatenate((columns_to_keep, MUST_HAVE_COLUMNS))] if should_keep else df\n",
    "df['YieldBucket'] = pd.Series(pd.qcut(df.Yield, q=3, labels=[\"high\", \"medium\", \"low\"]))\n",
    "print(\"The final dataframe has columns: \", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.get_dummies(df.YieldBucket).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.get_dummies(df.YieldBucket).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
